Hearing  aid.  In  ten  years  ago, I  first  tried  a  hearing  aid  and  it  was magical  to  lose  a  sense  and  gain  it  back  again. Felt  like  gaining  a  superpower. Ever  since  that  moment,  I've  been  on  a  hunt  for  ways  that technology  can  augment  human  capabilities and  give  us  superpowers. One  of  the  first  things  I  did  was  start  building prototypes  of  different  wearable  gadgets  and  Gizmos. Here  is  a  whole  tot  of  them, but  I  put  that  on  pause  to  focus  on building  software  for  Mac  iphone  and  soon  Windows. The  app  we  built  is  called  Rewind. It's  a  personalized  AI powered  by  everything  you've  seen,  said  or  heard. But  there's  so  much  more  to  life than  what  we  experience  on  our  devices. That's  why  the  next  step  humans  superpowers, is  the  rewind  pendant. Rewind  pendant  is  a  wearable  that  captures  what  you  say, what  you  hear  in  the  real  world, and  then  transcribes  crypts, and  stores  it  entirely  locally  on  your  phone. We  take  a  privacy  first  approach. First,  only  you  have  access  to  the  recordings  and  second, we  offer  features  for  you  to  ensure no  one  is  recorded  without  their  consent. Now  you  can  ask  your  personalized  AI about  truly  anything  you've  seen,  said,  or  heard. Head  over  to  rewind  pendant, to  sign  up  and  put  down a  deposit  for  your  rewind  pendant  for only  $59  So  it  seems  like  a  nice  product,  right? Okay.  So  let's  think  about  it. So,  you  know,  he motivates  that  first  by  talking  about  how, I  guess  he's  hearing  impaired, That's  what  it  sounds  like. And  so  he  has  trouble  hearing  people. And  so  he  built a  device  that  will  record  everything  that  people  say so  that  he  can  have  a  transcript  of  it  later  in case  he  didn't  understand. That  sounds  actually  like  a  very  useful  feature  to  have. Okay.  It's  going  to  be  privacy  first. That's  good.  So  all  of the  data  will  be  stored  locally  on  your  phone. Now,  he  doesn't  explain  how  anything  useful will  be  done  with  this  data  on  your  phone  because your  phone  cannot  run  PT  four, probably  there  are  going  to  be features  or  if  not  from  his  company, from  other  companies  that then  send  all  of  your  data  to  the  cloud  and then  P  four  processes  it  and  then  it will  tell  you  what  happened  in  the  conversation. Okay.  That  also  sounds  really  useful. Maybe  you  had  an  important  conversation  and you  want  to  do  some  analysis  on  it  later. Okay.  Are  there any  potential  drawbacks  to  this  technology? Yeah,  and  yeah,  I  don't  know,  maybe  not. But  yeah,  I  think we  see  what  some  of  the  issues  might  look  like  here. But  this  raises  a  broader  point, which  is  that  until  very  recently, there's  lots  and  lots  of  people  collecting  data about  people  who  operate any  website  that's  trying  to  make  money,  Google All  the  large  tech  corporations. Also,  various  agencies  of  the  US. Foreign  governments  well  documented that  they're  all  collecting as  much  data  about  us  as  they  can. Until  fairly  recently,  most of  that  data  was  pretty  useless. You  could  collect  all  the  tech  data that  you  wanted.  What  are  you  going  to  do  with  it? You  could  run  very  simple  classifiers  on, they  can  tell  you  is  a  positive  or  negative. I'm  going  to  do  very  simple  stuff  with  it, but  there's  nothing  actually  reliable  that  you  could  do. All  of  a  sudden  now  we  have  a  technology that  understand  language  at approximately  the  level  of  highly  intelligent  human. What  can  you  do  with  all  of the  data  that  has  already  been  collected  by us  and  that  will  continue  to  be  collected  about? I  don't  know  what  the  consequences  of  this  will  be. I  think  nobody  knows what  the  consequences  of  this  will  be. Something  for  us  to  think about  as  we're  talking  about  how  to build  this  technology,  okay? On  the  other  hand, there  will  be  lots  of  good  applications. I  think  there's  no  doubt  about  that. So  what  is  the  Social  stem  fraternity? They  sound  like  very  nice  people. Does  anyone  know  them?  No.  Okay. Well,  if  you  do  know  them, tell  them.  I'm  sorry. They're  taking  up  my  board. Let's  see.  So  last  time  we  were talking  about  squares  regression. Why  are  we  talking  about  regression  again? Because  it  turns  out that  all  of  deep  learning  is  just  regression. Or  at  least  all  the  deep  learning  we're  going  to be  doing  in  this  class  is  just  regression. We  have  a  dataset  D, It,  there's  a  bunch of  pairs  of  points  that  we've  collected. They'll  just  be  scalars  right  now, these  points,  x  one  is  a  scalar, y  one  is  a  scalar,  just  a  single  number. We  get  a  graph  that  looks  like  this. We  draw  a  line  through  that  graph  to  fit. We  intuitively  know  what  that  fit  should  look  like. What  we  saw  last  time  is  that  we can  formalize  what  that  means, what  a  nice  fit  looks  like according  to  the  least  squares  criterion. You're  going  to  find  the  line  where  when  you sum  up  the  distance  from  the  line  to  each  of  the  points, you  minimize  that  distance. That's  one  perspective  on  regression. Let's  just  say  this  loss  function again  because  we  want  to  keep  it  around. This  was  the  loss  function  that  we  defined, which  was,  we'll  assume that  our  dataset  has  n  points  in  it. That's  what  this  n  is  here. We're  going  to  sum  from  I  equals  one  to  n, the  square  distance  between  y, the  observation  that  we  made,  and  the, the  prediction  that  we  make, which  is  going  to  be  a  x  I  minus  B. We're  trying  to  find  the  theta, where  theta  is  just the  collection  of  these  coefficients,  a  and  B. We're  going  to  try  to  find  the  beta that  minimizes  this  quantity. This  is  one  way.  It  makes  sense visually  to  talk  about  it  like  this. But  there  are  situations that  you  can  get  yourself  into  where  there's no  easy  visual  interpretation of  what  you're  doing  anymore. We  have  a  clear  visualization  of  what  we  should do  when  our  problem  is  just  two  dimensional. We  have  a  single  x,  a  single. But  things  can  get  more  complicated, believe  it  or  not  predicted. All  language  is  just  a  regression  problem. But  like  I  don't  know  what  least  squares exactly  means  in  that  setting. Yeah,  x  and  y  will  introduce the  same  line  of  if  you  regress. Yeah,  so  let's  see, So  the  correlation  stays  the  same. There's  a  very  close  relationship  between  the  two. In  that  case,  what  is  the  coefficients  of  that  line? I  forget,  I  forget  the  exact  relationship. It's  basically,  can  get  one  from  the  other. There's  a  deterministic  relationship, I  forget  exactly  what  the  equation  looks  like,  okay? I  mean,  this  is  not  classified  linear regression,  so  this  is Linear  aggression  is  a  motivating  example for  what  we're  going  to  be  doing  in  deep  learning. Okay,  so  let's  talk about  a  way  to  generalize  what  we  did  here. We're  trying  to  find  a  principle  that will  carry  over  to  what  we're  doing  in  deep  learning. That  principle  is  called the  Maximum  Likelihood  Principle. What  does  the  Maximum  Likelihood  Principle  say? It  says  find  the  model that  maximizes  the  probability  of  the  dataset. This  does  not  look  anything like  squares,  at  least  on  the  surface. Let's  see  if  there's  a  connection. What's  the  motivation  for  this  principle? It's  saying  we  got  some  data  we  want  to  find the  best  explanation  for this  data  is  best  explanation  mean. It  means  like,  in  this  case, the  model  that  assigns the  highest  possible  probability  to  this  data. Think  about  this  in  the  context  of  language. We're  trying  to  build  language  models. Language  models  are  models that  just  predict  the  next  word. That's  what  we  learned  on  the  first  day  of  class. We  want  to  find  a  model  that maximizes  the  probability  of  the  next  words, the  actual  next  words  that  we  observe. The  highest  probability  that's  possible. It's  going  to  make  predictions  similar  to  a  human. That's  what  this  principle  is  saying. Let's  talk  about  this  in  the  context of  linear  regression. What  does  this  principle  mean? Here's  the  situation  that  we  assume  that  we're  in. In  the  case  of  linear  regression, we  have  an  observed  point Y  I,  that  we're  trying  to  predict. We're  going  to  assume that  this  point  was generated  through  the  following  process. What  does  this  mean?  It,  we  took  our  input  x  I, we  multiply  it  by  a,  we  added  B. And  then  what's  this  epsilon? This  epsilon  is  a  noise  term, So  we're  assuming  that  the  way  that  you get  each  YI  is  by  taking  the  x  I, doing  a  linear  model  on  top  of  the  is, and  then  adding  a  little  bit  of  noise. Okay,  we're  going  to  make  a  further  assumption, which  is  that  each  epsilon, let  me  actually  subscript  this  within  epsilon  I. It's  the  noise  that  was  generated  for  the, the  example,  each  epsilon, and  I'll  explain  what  this  notation  means, was  generated  from  a  normal  distribution with  mean  zero  and  stern  deviation  sigma. So  let's how  many  people  have  seen  the  normal  distribution  before? Okay,  so  you  all know  what  it  looks  like.  It's  a  bell  curve. Since  you're  all  subscribe  to  GPT  four, now  you  are  right. You  can  go  on  the  code  interpreter  and  just  ask  it  to generate  the  graph  for a  normal  distribution  for you  if  you  really  want  to  see  it. I  cannot  draw  for  my  life, and  so  I'm  not  going  to  be  able  to draw  a  good  bell  curve  for  you. In  past  years  I  would  try  and  fail, and  this  year  I'm  not  even  going  to. Okay,  we  have  all  of  this. The  epsilon  follows  a  normal  distribution. So  let's  just  rewrite  this  a  little  bit. I'm  going  to  just  rewrite  this  so  that  we  have a  nice  little  formula  here  for  epsilon. Epsilon  I  is  going  to  equal  Y  I  minus  a  minus  B. Okay,  We  have  a  formula  for  these. Epsilon  is  now,  what's  the  probability  of  my  dataset? Let's  talk  about  that.  I'm  assuming that  every  point  in  my  dataset was  generated  according  to  this  formula. That's  actually  enough.  I  now  have enough  to  say  for  a  fixed  a  and  B. What's  the  probability  of my  dataset?  How  would  I  do  that? How  would  I  calculate  the  probability  of  this  dataset  D, given  these  assumptions  here? Let's  assume  I  have  a  fixed  a  and  B. My  coefficients  are  fixed. Let's  say  this  another  way.  We  have a  line  here,  our  a  and  B. The  a  and  B  in  this  formula  determine  a  line. Notice  the  and  don't depend  on  the  particular  data  points. There's  no  subscript  next  to  them, so  we're  assuming  they're  fixed across  our  entire  dataset. Our  entire  dataset  was  generated  from  the  same  a  and  B. The  a  and  B  define  a  line. How  do  I  determine  the  probability  of  particular  points? Why  I  given  this? Yeah, On  normal  distribution. Okay.  So  I  think  there's  some  terminology, things  there,  but  I  think  we're  on  the  right  track. So  let's  say  that  I  have  a  single  point. Okay,  so  here,  let's  say,  let's  say  we're  down  here. So  here's  my  single  point. This  is  one  down  here. Then  I  have  a, this  is  Y  one  up  here. How  do  I  calculate  the  probability  of  that  point? I  have  X  one  is  an  input. My  model  says  I  can give  you  the  probability  that  Y  one  will  occur. How  do  I  do  this?  Yeah,  imagine a  normal  distribution  there  and  calculate  the  value. Do  them  okay. Okay,  I  think  good. So  there's  a  little  bit  going  on  with  the  thing, but  it's  good.  It's  good. I  like  the  answer,  so  I  will  unfortunately  have  to draw  a  normal  distribution  that  wasn't  the  worst. I  mean,  you  can  see  it's  off  center.  It's  pretty  bad. It's  not  the  worst  ever. Okay.  So  what  do  we  do? What's,  let's  say  that the  distance  between  this  Y  I  and  the  line. I  don't  know  what  that  distance  is. Let's  say  it's  equal  to  two. Okay? What  do  I  do?  That  distance I  know  has  to  be  equal  to  epsilon  one. I'm  going  to  go  out  onto my  bell  curve  and  I'm  going  to  find  where  does  two  occur, Maybe  the  curves  right  here. The  bell  curve  tells  me  what's the  probability  of  that  occurring. This  is  the  probability  of  you  getting  a  two. That's  the  probability  of  my  data  point. It's  whatever  this  point  on  the  bell  curve  was. I'm  going  to  go  through  my  entire  dataset. I  have  a  bunch  of  other  points. So  this  is  my  residual  for  point  I. I'm  going  to  calculate  the  residual  for every  other  point  in  my  dataset. I'm  going  to  ask,  I'm  going  to  go  over  to my  bell  curve  and  then  ask  what  was the  probability  of  that  residual that  gives  me  the  probability  of  the  dataset. Okay,  so  probability  of  the  dataset  given, Well,  I  actually  have  to, there's  a  little  bit  of  notation funniness  I'm  going  to  do  here, but  it's  fine  for  right  now, given  theta  the  probability  of  my  data  set. So  I'm  going  to  take  each  point, I'm  going  to  compute  this  probability. What  do  I  do  after  that?  So  I'm  going  to compute  the  probability  of  each  individual  point. What  do  I  do  that  with  that  afterwards, multiply  them?  That  sounds  right. What  assumption  am  I  crucially  making when  I  multiply  the  probability  of  all  those  points? Yeah,  they're  independent. They  might  not  be.  The  assumption everywhere  in  deep  learning  though  is that  when  you  have  individual  points, not  just  deep  learning,  machine  learning,  basically, it's  that  when  you  have  individual  points, they're  all  independent  of  each  other. And  then  you  have  to  say,  what  is an  individual  point  in  natural  language processing  these  days, an  individual  point  is actually  going  to  be  like  an  entire  text. Maybe  somewhere  2000-100  thousand  words. That  will  be  like  one  data 0.100  thousand  words  around  the  size  of  a  book. Somewhere  between  a  short  essay and  a  book  that's  a  single  data  point. But  then  you're  going  to  assume  that  each  book, or  whatever  text,  is  independent  of  each  other. And  to  get  the  probability  of  those  things, you'll  multiply  them  together. Here,  we're  going  to  assume. Each  individual  point  is  independent. It's  going  to  be  the  probability  y1x1 and  theta  times  all  the  way  up  to the  probability  of  y,  x,  and  theta. We  can  write  that  in a  slightly  more  concise  way  using  this  Pi  notation. Probability  of  y  x  theta. Now  we  just  need  to  say  what  is  the  probability  of? Remember,  all  that  we  care  about  is the  probability  of  our  residuals. That's  going  to  give  us  the  probability  of a  particular  data  point  given  in  X  I. What's  the  probability  of  these  residuals? Y  given  X  theta. That's  equal  to  probability  of  epsilon  I  given  theta. Actually,  the  fata  doesn't  even  matter  here. Epsilon  I  is  a  residual. It  doesn't  depend  on  A  and  B  anymore. It's  actually  just  what's  the  probability  of  epsilon  I? The  way  that  we  get  the  probability  of a  residual  is  by  looking  at  the  bell  curve. What's  the  formula  for  the  normal  distribution? Epsilon  I  is  sampled  from  a  normal  distribution. That  implies  that  the  probability of  epsilon  I  is  equal  to, and  this  is  just  the  formula  for  the  normal  distribution. This  thing  out  front  doesn't  matter  all  that  much, in  the  sense  that  we're  going  to  be able  to  ignore  it  in  most  of  our  later  calculations. To  be  fully  mathematically  correct, we  have  to  include  it  here. We  don't  really  need  to  worry  about  it. It's  the  stuff  inside of  the  exponent  that  we  actually  do  need  to  worry  about. Make  that  a  little  clearer. We  have  to  this  thing  that's  in  the  exponent, we're  going  to  take  epsilon, we're  going  to  square  it  and divide  it  by  the  standard  deviation  squared. Those  would  be  actually  important operations  that  we're  doing. What  that  means  is  that  the main  consequences  of  the  nose, there's  a  minus  sign  on  the  outside, because  there's  a  minus  sign. The  larger  and  magnitude  epsilon  is, that  means  the  smaller  the probability  of  that  noise  will  be, that's  the  main  thing  we  need  we  need  to care  about  here.  Any  questions? Yes. Could  you  explain  what  the  probability  question. Which  one?  Here? Sorry.  This  is  what  I'm  saying  is  that  I'm  taking the  probability  of  the  first  data  point  and multiplying  it  by  the  probability  of  second  data  point, by  the  probability  of  the  third  data  point,  and  so  on. The  probability,  yeah.  So  I  go  through, I'm  looping  through  the  dataset  here,  okay? I'm  just,  my  dataset  is  pairs  of  XI,  YI. I'm  looping  through  those, multiplying  the  probability  of  each  data  point. This  probability. You  want  a  more philosophical  answer  about  what  this  means, is  that  it's  a  good  question. What  is  this  probability? Let's  think  about  this  in  the  context  of language  probabilities  in  language. And  we'll  be  returning  to  this  throughout  the  class. Probabilities  in  language  come from  a  bunch  of  different  places. People  just  say  random  stuff. That's  one  place  where  probability  comes  in. If  I  talked  to  you  twice, I  just  repeated  the  same  conversation with  you  twice  and  I  wiped  your  memory. Probably  say  a  little  bit  different  things  each  time. There's  some  probability  that's just  from  people  saying  random  stuff. That's  one  place  where  the  probability  comes  in. I  would  be,  I  could have  the  goal  of  building  a  model of  that's  coming  by  the  way. Building,  but  you  get  the  idea. I  could  try  to  build  model  of what  I'm  trying  to  do  is  at every  moment  predict  what  you're  going  to  say  next. You  in  particular.  There's  no  way for  me  to  get  it  exactly  right, but  I  can  get  it  better  than  chance.  Definitely. Okay. Yeah,  fraction. Just  sure.  Two  times. Two  times  pi.  Thank  you. Yes,  Station  of  our  dataset. So  I'm  not  saying  where  that  came  from. You  can  either  estimate  it  or  you  can just  fix  it  ahead  of  time. I'm  assuming  here  that's  fixed  ahead  of  time. It's  just  the  number  I  pulled  out  of  a  hat. Great  question.  Yeah,  squares. Making  the  math.  Is  there  a  reason  why you  chose  the  list  from  our  line? Fantastic  question.  Yes,  that's  not  a  math  issue. That's  like  a  conceptual  issue. What  we're  assuming  there  is  that  the  XI's  are  fixed. We're  not  trying  to  model  the  distribution  of  the  XI's. What  we  care  about  is  saying  if  you  give  me  an  X, I,  I  want  to  make  the  best  prediction about  the  Y  I's  that  I  can. In  that  case,  all  I  care  about  is  the  vertical  distance. My  line  is  not  trying  to  model  the  great  question. Any  others?  Okay,  We've been  getting  some  very  good  questions. Okay?  I  have  a  formula  for  epsilon  here. Epsilon  I  is  equal  to  this  thing. We  can  just  write  it  out. It's  equal  to  one  over sigma  square  root  of  two  pi  e  to  the  negative  12. And  then  I'm  going to  be  taking  this  thing  and  squaring  it, that's  my  full  probability. What  I  want  to  do  is maximize  the  probability  of  my  dataset. I  want  to  find  the  A  and B  that  maximize  that  probability. It  turns  out,  if  I  try  to  solve that  problem  directly,  it's  hard. There's  something  that  I  can  do that  makes  it  much  easier. And  this  is  done  also, like  everywhere  in  machine  learning, that  thing  is  noticing  that  there's  an  equivalence. Okay?  So  if  I  want  to maximize  the  probability  of  my  dataset, get  the  same  solution  for  theta. If  I  maximize  the  log  probability. The  reason  is  that  whenever  the  probability  increases, so  is  the  log  probability. Log  is  a  monotonic  function. Monotonic  meaning  whenever  the  thing that  it  takes  as  an  input  increases, the  log  also  increases. Maximizing  one  is  equivalent  to  maximizing  the  other. Let's  do  that.  Let's  maximize  the  log  probability. Our  goal  is  going  to  be  to  maximize this  thing  log  probability  of  the  data  set  given  theta. This  is  equal  to  the  log  of  this  product  down  there. And  I'm  just  going  to  expand  what's  in this  product  to  be  what  was  over  here. This  is  the  pro  log  product  from  I equals  one  to  n  looping  over my  dataset  of  the  probability of  each  individual  data  point. That's  one  over  sigma  square  root  of two  pi  e  to  the  negative  12y. And  I'm  going  to  put  my  residual  up  here, Y  I  minus  x  minus  B  squared  over  sigma  squared. Notice  that,  well, there's  a  few  things  that  we  can  notice  here. The  first  is,  maximizing this  full  quantity  is equivalent  to  maximizing  this  quantity. Taking  out  this  thing  in  the  front. It's  just  a  constant,  any  theta  that maximizes  this  will  also maximize  this  with  that  term  removed. So  we're  just  going  to  get  rid  of  it. Our  new  goal  is  to  maximize. I'm  just  going  to  get  rid  of  that  thing. It's  now  e  to  the  negative  12y  I  minus, all  of  this  is  in  the  exponent. By  the  way,  what  can  I  do  with  a  log? The  log  of  a  product?  What  can  I  do  with  that? Okay,  great.  Some  of  the  logs.  Good. Okay.  And  I  have  log  of something  so  I  can  get  rid  of  the  log  in  the  E, and  now  the  xponent  drops  down. So  this  is  equal  to  a  sum  from  I  equals  one  to  n of  negative 12, okay? I  want  to  maximize  this  thing. Notice,  maximizing  this  doesn't  depend  on  sigma. It  doesn't  depend  on  the  one  half  I  want  to  maximize. Equivalently,  I  want  to maximize  the  sum  from  I  equals  one  to  n of  negative  Y  I  minus  a  x  I  minus  b  squared. I'm  almost  done.  The  final  thing that  I  note  is  I'm  trying  to maximize  a  negative  quantity. Here,  I'm  maximizing  negative  of something  that's  equivalent  to, let's  say,  make  this  as  close  to  positive  as  I  can. Another  way  of  saying  that  is  I  want to  make  the  negative  of  that  as  low  as  possible. This  is  equivalent  to minimizing  the  sum  from  I  equals one  to  n  of  this  thing. Do  we  recognize  this?  What's  this? It's  over  there.  That's  just  least  squares. Maximizing  likelihood  in  this  particular  case is  equivalent  to  doing  least  squares. Now  that  equivalence, the  main  reason  it  holds  is  because  of  this  assumption that  our  noise  was distributed  according  to  our  normal  distribution. If  we  did  not  make  that  assumption, we  would  not  get  this  equivalence  anymore. It's  a  natural  assumption  to  make. We  see  that  there  is  an  equivalence  here. The  nice  thing  about  maximum  likelihood  though  is  that  it generalizes  farther  then  least  squares. So  what  we're  going  to  be  doing throughout  is  just  going  to  be  maximum  likelihood, but  this  is  how  we  can  think  about  motivating this  principle.  Any  questions? No. Okay.  Okay. Yeah. How  is  the  distribution  of  the  P  like  everything  else? Look,  I'm  trying  to think  of  a  diplomatic  way  to  put  this. That  there  are  people  who spend  their  careers  trying  to  think about  ways  to  justify  assumptions  like  this. So  we  don't  know.  Yes. Okay. I'll  put  it  another  way. That's  a  little,  I  mean,  people  do  what works  and  we  know  what  works. We  don't  necessarily  know  why  it  works, but  it's  not  like  people  are  simply  shooting  in  the  dark. They  have  recipes  and the  recipes  happen  to  turn  out  tasty  dishes. Let's  talk  about  a  generalization of  just  normal  univariate  when  your  regression. So  let's  talk  about  multivariate  regression. Everything  that  we're  going  to  encounter  in deep  learning  is  multivariate. What  does  multivariate  mean? This  term  means  multiple  input  features. Our  xs  are  now  not  single  numbers,  they're  vectors. Our  dataset  now  looks  like  this. So  your  goal  maybe is  you're  going  to  look  at  somebody  and you  want  to  predict  how  many  babies  they  have. Okay,  you're  right. Okay,  yes,  we're  going  to  make  it  nice. It'll  be  nice.  And  you  get  two  input  features. So  you're  not  allowed  to  just  look  at  anything. You're  going  to  be  looking  at  number  of  diapers  used  per day  and  hours  of  sleep. So  we  can  call  this  feature  x  one  and  this  feature  x  two. We  can  think  about  developing  a  function  that will  predict  this  quantity  from  these  two  quantities. In  multivarier  linear  regression, we're  going  to  keep  that  function  linear. It's  going  to  be  a  line,  so  we're  going  to  have function  take  his  input,  x  one  and  x  two. Where  you  get  out  and  we'll use  our  function  is going  to  look  like  this. We're  going  to  be  trying  to estimate  numbers  W  one  and  W  two. That  give  us  as  great  predictions  as  possible. We  can  think  about  representing a  single  data  point  as  a  vector. And  by  the  way,  notice the  x  one  and  x  two  here  are  not  vector. So  I  don't,  I  mean, they're  not  these  things,  right? These  things  are  pure  vectors. These  things  down  here  are  scalars. Okay?  So  I  don't  mean  the  same  thing  here. We  have  x  as  a  vector. We're  going  to  collect  it  up, the  x  one  and  x  two.  These  two  features. Okay,  we're  going  to  treat, we  can  think  about  these  as  our  parameters,  our  weights. W  is  also  a  vector. We  can  rewrite  our  equation  here  in  a  vectorized  form. We  can  say  that what's  this  here  that  I  did  transpose? Because  I  need  to  make  sure  the  dimensions  match. Okay,  good. We  can  think  about  generalizing this  to  an  arbitrary  number  of  features. Let's  say  K  input  features. We're  going  to  take  each  of  the  K  input  features, multiply  it  by  some  weight  or  some  parameter  W. Then  add  a  constant  B  at  the  end. Still  a  linear  function  in  the  sense  that  all, all  that  we're  doing  with  the  input  features is  multiplying  them  by  a  scalar. We  can  think  about  Co.  Now  our  dataset, the  xs  are  actually  these  big  vectors. Each  x  I  is  a  big  vector. X  one  vector  is  equal  to. We  need  a  notation  for  this. The  notation  is  unfortunately  ugly.  We  need  subscripts. That's  life.  We  need  lots  and  lots  of  subscripts in  this  class  because  we're  going  to be  dealing  with  big  matrices. Here  is  the  not  that  we'll  be  using. How  do  we  interpret  this?  This  is the  first  data  point  in  our  dataset. It's  going  to  be  a  collection  of  input  features. The  input  features,  what  this  is  saying  is  this  is the  first  input  feature  from  the  first  data  point. This  is  the  second  input  feature from  the  first  data  point. That's  what  the  two  subscripts  mean. The  first  subscript  indicates  which  data  point  are  you, the  second  one  indicates  which  feature  are  you. X  two  is  going  to  be  a  similar  vector. We  have  n  total  points  in  our  dataset. We  can  collect  all  of  these  things  into  a  matrix  X. What's  X  is  a  matrix where  each  column  will  be  filled  up  by  these  things. These  are  column  vectors, and  we're  filling  up this  big  matrix  X  with  n  of  these  column  vectors. What  are  the  dimensions  of  this  new  matrix, K  by  K  by  K  columns? We're  also  going  to  collect  up  all  of  the  outputs. The  Ys  I'm  keeping  as  individual  scalers still  I'm  going  to  call  this  big  Y is  equal  to  these  end  points  here. The  general  problem  is  still  the  same. We're  trying  to  a  number  of  babies  that  someone  has. Now  we  get  to  look  at  many  more  features. We  get  to  look  at  maybe  100  or 1,000  different  features  and  predict, this  is  something  that lots  of  companies  are  trying  to  predict  about  you, by  the  way,  because they're  going  to  be  targeting  their  advertising. I  did  not  get  diaper  advertising before  having  a  baby  and  now  it's  a  thing, There's  a  reason  why  I'm  getting this  targeted  advertising. We're  trying  to  use  as  many  input  features  as  we can.  Number  of  babies. One  of  these  is  here  X  one, This  represents  the  first  parent. And  their  features  X  two  represents  the  second  parent. And  then  we're  going  to  be  trying  to  predict this  given  these  input  features. Okay,  then  finally,  we  need to  collect  up  our  weights  into  a  weight  vector. There's  going  to  be  weights, one  weight  for  each  feature. We  can  think  about  these  weights  as  indicating basically  which  features  are  most  important. That's  what  the  magnitude  says. And  then  the  direction  says, does  this  weight  make  you  more  or less  likely  to  have  a  baby? Or  does  it  increase  or decrease  the  number  of  babies  that  you  have? Okay,  now  I  would  like  to  write  in  form  a  formula for what's  my  assumption. I'm  making  an  assumption  about  how  the Y's  are  generated.  It's  a  line. What  is  that  assumption? Or  was  it  look  like  you're  in  matrix  form? So  it's  going  to  be  y  equals  what. Yeah,  multiplications. It's  not  going  to  be,  it's  going  to  be  a  normal. I  think  you're  on  the  right  track, but  it's  going  to  be  a  normal  sort of  matrix  vector  multiplication. Yeah,  we  could  do  that. Will  give  us,  what  will  that  give  us? Will  that  give  us  why  we  could  do  that? It  will  give  us  y  transpose. That'll  give  us  a  row  vector rather  than  a  column  vector.  So  what  do  I  need  to  do? I  need  to  take  the  transpose  of  x  instead. To  get  this  column  vector  here, I'm  going  to  take  the  transpose  x. Multiply  it  by  a. Done.  Yeah,  plus, great,  this  is  correct. But  there's  something  very  funny and  actually  incorrect  about  it. It'll  be  correct  for  this  class, but  if  you  think  about  it  hard  enough,  it's  incorrect. What's  the  issue  here? What's  intercept  is  an  intercept,  but  what  type  of  thing? It's  a  number  and  it's  an  intercept. So  that  means  it's  a  single  number. What  type  of  thing  is  this? When  I  multiply  them  together,  what  is  it? This  is  equal  to  what  are  the  dimensions  of  x  times? Where  are  the  dimensions  of  that  n  by  one? It's  a  vector,  This  is  an  n  by  one  vector. I'm  adding  a  scalar  to  that  thing.  What  does  that  mean? We  all  know  what  it  means.  It  means  that  you  go  through every  number  in  this  vector  and  you  add  to  it. That's  the  convention  in every  deep  learning  library  that's  out  there. And  we're  going  to  be  using  this  convention. But  we  have  to  notice  that  we're  doing  something  here. When  we  add  a  and  a  scalar, that  means  add  the  scalar  to every  number  in  the  vector  that  process. This  thing  is  called  broadcasting. We're  broadcasting,  the  arithmetic. You  can  also  broadcast multiplication  if  we  had  multiplied  by  B, that's  a  little  bit  more  normal,  okay? We  just  need  to  notice  that  this  is  happening  so that  we  know  what our  systems  are  doing  when  we're  working  with  them. Any  questions? Yeah,  we  could.  But  it's  nice  when. It's  a  little  funny  to  do  that though  because  all  of  the  S  will  be  the  same. Like  we  actually  don't  think  about  this  in terms  of  minimizing  your  memory  consumption. You  don't  want  to  have  to  store duplicate  copies  of  the  same  information. Any  other  questions? We  could  write  a  formula  for doing  least  squares  multi vary  linear  regression.  We're  not  going  to  do  that. Main  purpose  here  was  to  demonstrate the  matrix  form  of  this  problem  because  we're going  to  want  to  turn  our  later  problems into  big  matrix  multiplication  problems. Let's  start  talking  about  logistic  regression. By  the  way,  have  people  started  on  the  problem  set? Yeah,  is  it  fun? Yeah,  you've  probably  never had  a  problem  set  like  this  before. I  strongly  suspect  I've never  assigned  a  problem  set  like  this  before. I'm  excited  to  see  how  it  turns  out everyone  you  know  a  good  faith  effort  with  it. Look,  there  could  be  rules  to  bend  here.  I  don't  know. There's  no  way  to  us  working  together. This  is  like  a  complex  system  and  there's  no  way  to  know how  a  complex  system  will operate  until  you  actually  operate  it. We  don't  know  how  this  experiment  is going  to  turn  out  with  this  first  problem  set. If  everyone  makes  a  good  faith  effort  though, then  we  can  have  more  fun  problem  sets  like  this for  the  rest  of  the  quarter  I'm  hoping  for, as  I'm  sure  you  will,  making a  good  faith  effort  towards  this. Let's  talk  about  logistic  regression. Logistic  regression,  further  generalization of  linear  regression. Probably  many  of  you  have  seen  it  before. We  need  it,  we're  going  to  be  working  with  it  every  day. The  simplest  type  of  logistic  regression  is  used  to solve  binary  classification  problems  like  this. On  the  x  axis,  we  have  an  input  feature, number  of  snuggles  that  are  observed  on  the  Y. It's  the  number  of  wolf. Where  are  my  Es  and  where  are  my  Y's? Think  we  can  figure  that  out  there. Dogs  and  cats.  Okay. I  mean,  we  do  see  the  occasional  cat  woofing, I  don't  know,  had  something  wrong  with  it. But  in  general,  we  see there's  a  fairly  clear  relationship. As  you  get  more  of  either  of  these  features, you're  more  likely  to  be  a  dog. They're  both  good  features  to  have. Our  dataset  in  this  case  looks  very  similar  to  before. With  one  major  difference, we  have  a  vector  of input  features  and  a  single  output  feature that  we  want  to  predict. The  main  difference  is  that  each  Y I  is  assumed  to  be  either  zero  or  one. We're  trying  to  predict  a  binary  label. We  can  formulate  logistic  regression  as  just  a  very, very  slight  generalization of  multivariate  linear  regression. We're  going  to  have  our  parameters, we  have  another  parameter  B, these  are  our  parameters  that  we're  trying  to  learn. Then  what  we're  going  to  say  is  that the  probability  that  y  I  is  equal  to  one. We  can  think  about  this  as  probability that  y  I  is  equal  to  one. We're  going  to  have  a  formula  for  this. We're  going  to  take  in  a  set  of input  features  and  try  to  predict  what's  the  probability that  something  is  a  dog  given  those  input  features. Probability  of  YI  equal  one  given x  I  and  our  coefficients, this  is  equal  to  e  to  the  dot  product  of  XI  and  plus B  over. This  is  our  formula. There's  a  slightly  different  way that  we  can  write  this  formula, which  is  using  the  sigmoid  function. The  sigmoid  function  takes  in  a  number  z  and  maps that  to  over  one  plus  e  z. We'll  get  back  to  the  sigma  function, I  just  wanted  to  mention  that  here. Another  way  of  writing  this  is  let's  put  that  over  here. So  then  that  means  this  is  equal  to sigmoid  of any  questions. So  let's  try  to  get  an  understanding  of  this. What  happens  when  Z  is  very negative  in  the  sigmoid  function? Yeah,  the  probability  gets  very  close  to  zero. That's  right.  So  that's  correct. So  I  mean,  I  wouldn't  call  it  the  only  thing, the  only  difference  is  that  I  wouldn't  say  it's the  answer  because  yeah,  the  output. Exactly,  Exactly. Okay.  What  happens  when  Z  is  very positive  Approaching  approaching  one. Okay. So  let's  just  draw  a  little  graph here  of  the  sigmoid  function. I  don't  know,  Let's  pretend  that  this  is  okay. It's  pretty  terrible,  but  it's  okay. Okay,  What  happens  when  z  is  equal  to  zero? That's  meant  to  be  this  point  over  here. What's  this  point  over  here? When  z  is  equal  to  012. Okay?  Sigmoid  of  zero  is  equal  to  1/1  plus  one, which  is  equal  to  12.  Okay? We're  going  to  be  the  X, the  features  that  we  got, taking  the  product  of  them  with  these  weights. W  here,  adding  B  and  running  that  through  a  sigmoid, that  gives  us  the  predicted  probability that  something  is  a  dog. What  I  want  to  do  now  is  get a  visual  picture  of  what's  going  on  in  this  process, I  mentioned  that  the  sigmoid  function and  logistic  regression, they're  used  everywhere  in  deep  learning  in  our  course. It  turns  out  that  the  output  layer  from GPP  for  every  other  neural  network that's  used  for  understanding  language, The  output  layer,  that's  the  final  layer, is  a  logistic  regression. It's  the  sigmoid  function. It's  a  logistic  regression. Really?  We  see  this  everywhere. It's  good  to  have  some  idea about  what  this  function  is  doing. Let's  suppose  that  we're in  a  situation  where  the  probability, something  being  a  dog,  is one  half  probability  that  y  is  equal  to  one  given  x. For  convenience,  I'm  going  to  drop the  W  and  B  terms  in  this  probability  expression  here. The  probability  that  W  is equal  to  one  given  x  is  equal  to  one  half. Why  is  this  implied?  What  this  means  is  that  12  is equal  to  E  times  x plus  b  over  one  plus  W  times  x  plus  b. We've  already  seen  the  point where  the  sigmoid  function  is  equal  to  12. We  know  that  the  z  has  to  equal  zero  in  that  case. That  means  this  thing  here  has  to  equal  zero. This  implies  that  this  is  equal  to zero  times x  is equal  to  negative  b. If  we  want  to  understand  the  situation, what  we  want  to  think  about  is which  sort  of  objects  will  we  encounter? We're  trying  to  classify  objects  into  cats  and  dogs. Which  sort  of  objects  will  we  encounter  that are  equally  likely  to  be  a  cat  or  a  dog? Those  are  weird  objects. I  don't  know  what  situation  that  happens, but  in  this  scenario,  that's  what  we're  saying. You're  equally  likely,  we  want  to  find  all  of the  S  that  satisfy  this  relationship. Those  are  the  Xs  that  are  equally likely  to  be  one  or  the  other. What  can  we  say  about the  S  that  satisfy  this  relationship? Let's  imagine  that  is  equal  to  zero. They'll  make  it  a  little  bit  easier  for  us. Let's  set  equal  to  zero. What  we  have  there  is  that  times  x  is  equal  to  zero. Which  xs  satisfy  this  relationship? Why  is  this  equation  tell  us there's  a  geometric  interpretation  for  it? Yes,  it's  been  a  while  the  worth,  They're  all  orthogonal. So,  we  need  to  understand  linear  algebra, at  least  up  to  this  point, a  little  bit  more  than  this,  but  this  is definitely  a  must  for  our  understanding. Let's  suppose  this  is, I  could  have  chosen  a  different, let's  choose  this  one  for  now. The  x  vector  x  that  satisfy  this  relationship are  all  of  the  points  that lie  along  this  line  that's  orthogonal  to  this  vector. These  are  the  points  such that  W  times  x  is  equal  to  zero.  Now  let's, I'm  just  going  to  make  this  line  a  little  bit  longer. Let's  suppose  B  is  equal  to  one. Let's  actually  negative  one. Let's  say  negative  one  now.  So  why  does  this  mean? Because  B  is  equal  to  negative  one, then  the  condition  that  we  set  over  here  is times  x  is  equal  to  one. Okay? Which  points  x  are  such  that  times  x  is  equal  to  one. Yeah.  Did  you  I'm  sorry. Are  there  as  x  on  Yeah.  Such  that  this  is  true. I  not  quite,  because  if  we  take  all  the  points  on  W, then  there  will  be  one  point  such  that  when  you multiply  this  by,  it  will  equal  one. But  then  the  other  points  are  going to  be  bigger  or  smaller  than  that. But  you're  right,  there's  something  about measuring  a  long  that's  very  important. That's  entirely  correct. Let's  make  a  further  assumption. Let's  say  that  the  magnitude  of  how  big  the  vector  is, that  this  is  itself  equal  to  one. This  is  a  vector  pointing  in this  direction  whose  magnitude  is  equal  to  one. Give  me  one  vector  x  such  that  this  condition  is  true. Slut  magnitude,  correct,  when  its  magnitude  is  also  one. If  this  is  true,  then  there  is  a  vector  x,  one  solution. Let  me  say  this  is  an  assumption  that  we're making  one  solution  x  is  equal  to. That  means  right  here, this  would  be  one  solution  to  the  problem. Where  are  the  other  solutions? Yeah,  it's  like  a  linear  combination of  that  and  anything  along  that  line. Exactly.  And  visually,  is  that  exactly? I'm  going  to  take  this  point  and add  any  point  along  this  line. That's  exactly  right  now. What  is  the  result  of  that  look  like? What  is  the  result  of  adding this  to  any  point  along  this  line look  like  that  it  just  shifted, so  I  just  find  a  parallel  line  to  this. So  this  is  the  set  of  points, W  times  x  is  equal  to one.  So  what  does  this  tell  us? Okay,  Now  suppose  that you  have  a  point  that's somewhere  on  this  side  of  this  boundary. Okay?  So  you  have  a  point  over  here. So  you're  on  this  side  of  this  boundary. What  do  you  immediately  know about  the  probability  that  that,  that  point  is  a  dog? You  have  a  point  over  here. What's  the  probability  of  this  point  is  a  dog? I  mean,  not  exactly, We  don't  know  that,  but  what  do  we  know  qualitatively? Yeah.  No,  it's  not  necessarily  one. It's  more  likely  than  not to  be  a  dog.  I  think  that's  what  we  know. The  exact  magnitude  is  important, but  what  we  know  qualitatively, it's  more  likely  than  not  to  be  a  dog. So  in  other  words,  we  can  think  about  this  12, the  set  of  points  that  we're  trying  to  find. The  set  of  x  such  that this  probability  of  y  equals  one  given  x  is  equal  to  12. We  can  think  about  the  set  of  xs  that satisfy  this  constraint  as  a  decision  boundary. If  you're  on  one  side  of  this  decision  boundary, you're  more  likely  than  not  to  be  a  dog. If  you're  on  the  other  side  of  this  decision  boundary, you're  more  likely  than  not  to  be  a  cat. Logistic  regression  defines  a  linear  decision  boundary, That's  the  crucial  thing  about  it. You're  trying  to  carve  up  the  space  of  things, potential  cats  or  potential  dogs. You're  trying  to  carve  it  up  using  a  line, so  that  on  one  side  of  the  line  is  one, On  one  side  of  the  line  is  the  other. The  funny  thing  about  this  is like  when  you  look  at  this  math, you  don't  immediately  see  that  there's  a  line  involved. Or  at  least  that  you're  trying  to find  a  linear  decision  boundary. But  in  fact,  that's  what  this  turns  into. Any  questions  about  this? No. Okay. So  one  final  topic  I  wanted  to  cover  today, which  is  Einsup  is the  final  couple  of  problems  on  your  problem  set. Why  are  we  doing  Eins?  It's  because when  we're  trying  to  program  in  deep  learning  packages, everything  in  deep  learning  is  matrix  multiplication. The  matrices  though,  are  not  matrices  anymore. There  are  things  with  three  and  4.5 dimensions  in  them  by which  it's  not  like  a  four  by  five  matrix. It's  a  four  by  five  by  six  by  seven  tensors. These  extremely  complicated  generalizations  of  matrices. They're  not  going  to  turn  out  to  be  very  complicated, but  we  need  a  clean  way  to  manipulate  them, which  means  Einstein  notation is  the  best  way that  I've  found  to  work  with  these  things. I  get  very  confused  when  I  have  to work  with  these  high  dimensional  things. Without  Eins,  I  get  much less  confused  when  I'm  using  Eins. A  lot  of  the  field  agrees  with  me  about  this. You'll  see  it  in  a  lot  of  places. If  you  end  up  doing  more  deep  learning  programming, How  does  Eins  work? Let's  suppose  that  we  have  a matrix  x  that  looks  like  this. A  vector  y  that  looks  like  this. I  want  a  notation  for  this. The  way  that  we're  going  to  think  about  this  is not  in  terms  of  this  produces  a  vector. It's  a  matrix  by  times  a  vector. The  way  that  we're  going  to  think  about  this  thing  is that  we're  not  going  to  think  about  the  entire  object. We're  going  to  think  about  how  to construct  a  specific  index, a  specific  part  of  the  resulting  vector. What  does  this  look  like?  It  looks  like  one  times five  plus  two  times  six. That's  going  to  be  the  first  row. The  second  row  is  going  to  be  three  times  five, plus  four  times  six. Let's  think  about  how  to  construct. Let's  call  the  result  of  this. Okay,  let's  call  it  for  right  now.  That's  fine. This  is,  it's  a  vector. Let's  talk  about  what  z  one  is  equal to  z  one  is  the  first  index  here,  the  first  row. This  is  equal  to  one  times  five  plus  two  times  six. Let's  write  this  in  a  slightly  more  general  way. I'm  going  to  be  summing  over  something. When  am  I  summing  over? When  I'm  doing  this,  I'm  summing  over the  columns  in  x  and  the  rows  and  y. Here's  another  way  of  saying  this. I'm  summing  over  K, I'm  getting  x  one. I'm  sticking  to  the  first  row  in  x, the  column  in  x.  I'm  multiplying  that  by the  row  in  y,  z. Two  very  similar  formula. This  is  a  sum  over  k, where  k  is  again  the  columns  of  x, the  rows  of  y,  except  now  I'm focusing  on  the  second  row  of  x. This  is  going  to  be  x2k  times. Y  K,  there's  a  lot  of  indices  floating  around  here. You're  probably  going  to  want  to  do, think  about  this  offline, but  once  you  get  the  indices  clear  in  your  head, this  way  of  thinking  about  it  should  be  fairly  good. Okay,  we  have  now  a  different  way. A  new  way  of  writing  down  the  result  of  multiplying a  matrix  by  a  vectors is  just  another  way  of  writing  this. That's  what  einsum  is. Eins  says  is  how  do  you  construct the  ith  element  in  the  result  of  this? You  want,  I  want  one  or  two. I  have  z  one  and  z  two. How  do  I  construct  in  general? The  way  that  I  construct  is  by  summing  over  k, and  it's  going  to  be  X  times  Y  k. That's  how  I  get  I.  In  general, what  we  can  do  is  we  can  just  think  about  this  pair. Producing  this  pairs  is just  another  way  of  writing  exactly  this  equation. We  changed  the  order  slightly, but  Eins  notation says  Xk, Y,  K  produces  right  arrow,  Z  I. If  you  want  to  understand  what a  notation  like  this  means, you  say  the  thing  on  the  right  isn't  an  equal  sign. The  things  on  the  left  multiply  by  each  other. There's  one  missing  detail  there. What  is  it  where  did  the  summation  come  from? The  rule  is  that the  rule  for  interpreting  Einsum  notation, which  is  sum  over  any  index  that does  not  appear  on the  right  hand  side of  the  arrow. There's  one  index  that  appears  on  the  right  hand  side, and  there's  one  index  that  does  not  appear. The  I  appears  in  the  Z  I. The  K  does  not  appear  there. That  means  we  sum  over  k.  The  way to  think  about  Einsum  is  that  it's  giving  you a  way  to  construct  an  entire  matrix, or  an  entire  vector  out  of the  individual  pieces  of  that  vector  matrix. It's  saying,  what's  the  rule for  constructing  those  pieces? Let's  end  here.  I'll  see  everyone  on  next  week.
