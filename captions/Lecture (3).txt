Okay.  Couple  of  announcements. If  you  look  at  the  syllabus, the  first  problem  set  is  being  released  today. Yes.  So,  first  problem  is  being  released  today. Our  other  TA,  I  mentioned  we  have  two  TA's  in  the  class. There's  no  and  then  also that's  we'll  be  releasing details  about  office  hours  today. They're  going  to  start  later  in  the  week. Any  other  questions  about  class  logistics, how  things  are  going  to  be  run? I  do  have  a  mice  on  right  now. Yeah,  I  thought  this  room  was  miked  up. That's  But  apparently  it's  not. Any  others?  No.  Okay. I  want  to  think  for  a  second  about the  AI  tutor  project  that  all  of you  are  going  to  be  doing  that's  really a  priority  for  this  class. I'm  excited  to  see  how  it  goes. I  want  everyone  to  start  thinking about  it  sooner  rather  than  later. By  the  way,  if  you've  never  used  four  before, you've  never  talked  to an  AI  in  the  way  that  I'm going  to  talk  to  GPT  four  right  now. That's  actually  one  of  the  major  skills I  want  you  to  learn  in  this  class, which  is  how  to  talk  to the  system  and  how  to  get  the  most  out  of  them. Let's  think  strategically  about  a  particular  question. I  want  to  design  an  AI  tutor for  class  on  deep  learning for  natural  language  processing. Tu  could  potentially  have different  capabilities  and  be focused  on  solving  different  tasks. What  are  some  of  the  high  level  options  that  I  have  for designing  such  a  tutor with  respect  to  its  goals  and  desired  outcomes? I'm  not  asking  here  like  mechanically, how  do  I  build  a  tutor? I'm  not  asking  what's  my  software  stack  look  like. What  I'm  asking  is, what  am  I  trying  to  accomplish  with  this  tutor? Let's  see  what  G  four  says. Strategic  intertwining  of  educational  theory, user  experience,  and  advanced  technologies. Let's  see,  curriculum  design, embedded  structure,  curriculum  that progressively  builds  on  previous  knowledge. Adaptive  learning  pathways  implement algorithms  that  adapt  to  learning content  and  pace  based  on individual  student  progress  and  performance. Real  world  applications. Okay,  this  is  actually  not  what  I  am  asking  for, talking  about  our  features.  And. Not  what  I  want  right  now. Eventually  we'll  have  to  talk  about  features of  the  system  and  these  are  high  level  features. That's  good,  but  it  still  doesn't  actually  answer  like, what  is  my  tutor  trying  to  accomplish? There's  a  lot  of  good  details  here. This  is  all  stuff  that  you  probably  want  to  keep  in  mind. But  I'm  not  happy  with  this  answer. When  am  I  going  to  do,  because I'm  not  happy  with  this  answer. One  would  be  to  just  give  up. Sometimes  a  reasonable  strategy  in  this  case  though, this  system  four  obviously  knows  a  lot about  this  topic  or  it's  able to  think  very  well  about  this  topic. I'm  not  going  to  give  up  quite  yet. I'm  going  to  tell  it  directly that  I'm  not  happy  with  its  answer. One  thing  that  a  tutor  could  do, and  I'm  going  to  give  you  an  example of  something  that  I  have  in  mind, is  replace  office  hours  for  Co. Instead  of  me  having  to  hold  office  hours, the  AI  tutor  will  hold  off  his  seers. That's  one  sort  of  thing that  you  could  ask  from  your  AI  tutor. Others  I  want  general  tasks, general  goals  that  this  tutor  could  have beyond  like  how  is  it  going  to  accomplish  them. Okay,  so  let's  try  to  get some  more  ideas  from  the  system. Okay,  I'm  telling  GPT four  exactly  why  I  was  not  happy  with  its  answer. And  I'm  giving  it  an  example  of  the  answer  that  I'd  like. High  level  strategic  goals  for  your  AI  tutor. Supplement  learning  support,  serve  as an  on  demand  2047  learning  resource  for  the  students. Okay,  that's  a  high  level  goal. Replace  or  augment  office  hours, facilitate  project  based  learning,  offer  guidance, resources,  and  feedback  during hands  on  projects  and  assignments. Create  personalized  learning  paths, identify  individual  learning  styles, pre  tailored  educational  journeys  for  each  student. Assistant,  evaluation  and  assessment. That's  an  interesting  one.  Basically,  automate grading,  that  would  be  nice. You  can  even  go  beyond  normal  grading  here. That's  actually  one  of  the  very  interesting  things. It's  not  like  grading, especially  a  state  university  like  UCSD. It's  very  limited  by  how  few TA's  you  have  for how  many  students  are  enrolled  in  your  class. You're  just,  did  you  get  this  right  or  not, you  could  imagine  something  much  more  personalized. If  you  have  an  intelligent  tutor that's  an  intelligent  grader  that's grading  your  work,  ensure  continuous  engagement. Implement  mechanisms  to  keep students  consistently  engaged, provide  nudges  and  feedback. I,  this  is  a  little  bit, it's  not  actually  saying  what  this  means  here. This  is  not  quite  as  nice  for  all  of  you. I  think  it  I get  like  an  eye  to  watch  over  all  of  you  basically, while  you're  doing  this  course, maybe  that  would  be  useful. Promote  peer  learning,  facilitate  guide  group  activities. Support  inclusive  education. Ensure  learning  materials  and interactions  are  accessible  and  adaptable  to  cater to  the  varied  needs  of  the  diverse  student  body. Career  guidance  and  skill  application, continuous  curriculum  up. Look,  these  are  great  ideas. I  wouldn't  have  thought  of  most  of  these. These  are  exactly  the  things  that  I  wanted. These  are  sort  of  things  that  you  can pursue  when  you're  developing  your  tutor. Your  tutor  should  have  a  high  level  goal. It  should.  This  course  is  a  big  thing,  right? There's  many  different  aspects  to  this  course. When  I  say  automate  me,  like  that's  the  goal. That  can  mean  many  different  things. You're  not  going  to  be  able  to  solve  all  of those  goals  during  the  course  of  one  quarter. What  you're  going  to  want  to  do  is  talk  to  GPT  four and  with  your  teammates  about  what  you  should  do. That's  the  very  first  step in  deciding  what  to  do  for  your  project. How  to  go  about  your  project. What's  your  high  level  strategic  goal? Which  aspect  of  the  class  or  of  teaching a  class  are  you  going  to  try  to  replace  or  improve? Yeah,  I  would  very strongly  recommend  talking  to  GPT  four  about  this  issue. And  part  of  talking  to GPT  four  about  a  question  like  this  is  learning how  to  talk  to  it  when  it's not  telling  you  something  that's  useful. You  need  to  explain  that  it's  not  useful  and  tell it  why  it's  not  useful.  There  was  a  question  here. Yeah,  here. Gpt  response. As  objective. But  what  I  want to  other  sections  besides objective  section  one,  section  three. But  at  the  same  time,  I  reminded  about  the  response. I'll  day,  I'm  not exactly  sure  what  you  mean,  these  are  different. I  mean,  these  are  different. It's  brainstorming  with  you,  right? So  it's,  it's  saying  here, here's  one  possible  objective  you  could  have, here's  another  possible  objective  you  could  have. If  you  if  this  is  not  the  information  that  you  want, then  you  need  to  tell  it  that you  want  some  other  piece  of  information. I  didn't  I  didn't  tell  it  to structure  its  response  this  way. This  is  how  it  decided  to  present  the  information  to  me. Yeah,  yeah. So  far  project,  is  it  okay  if  we  go  into something  that  super  specific  like  2047? Yeah,  supplement. Okay.  So  if  we  go  into  something  super  specific that  has  a  data that  just  I  mean, it  has  to  be,  I  mean,  I  guess, I  mean  just  targeting  one. So  let's  just  let's  say  that you  want  to  just  target  one,  that's  great. I  mean,  that's  a  very  big,  I  mean, my  main  concern  if  you  if  you  target one  is  that's  actually  an  extremely  broad  topic. What  does  it  mean  to  provide  2047  learning  support? You're  going  to  want  to  have  a  specific interpretation  of  what  that  means. I'm  asking  you  to  build  a  product,  right? And  the  product  has  a  purpose. The  purpose  has  to  be  understandable  by  its  users. Also,  you  have  to  be  able  to implement  it  over  the  course  of just  a  few  weeks  basically. I  think  those  are  the  main  constraints. I  would  say  a  well  focused  product is  what  we're  looking  for  here. Let's  talk  about  this. I  want  to  focus  on  one,  supplemental  learning  support. What  would  it  actually  mean to  implement  a  product  along  these  lines? Concretely,  what  can  people  in  the  back  read  this, by  the  way?  Yeah,  thank  you. What  would  this  product  do? Okay,  students  can  always  obtain  help, clarification,  and  extra  practice  whenever  they  need  it. Filling  gaps  and  reinforcing  learning without  relying  on  instructor  availability, question  resolution  so  students can  go  into  it  and  ask  questions. Additional  learning  material,  provide supplementary  materials like  articles,  videos,  and  tutorials. They  expand  on  course  content, personalized  study  aids assignment  help  concept  reinforcement. You  can  see  this  is  actually  extremely, there's  almost  no  way  that any  one  group  is  going  to  be  able  to  achieve  all  five of  these  in  your  project. I'd  say  implementing  one  thing, well,  that  would  be  the  best  outcome  here. Okay, so  what's  the  goal  here? We're  going  to  start  off  with  material  that I  basically  am  thinking  of  as  review  material. Some  of  you  may  not  know  it, which  is  why  I'm  teaching  it. Some  of  you  may  have  learned  it  in  some  other  classes. Maybe  you  remember  I'm  going  to  go  over  it. The  way  that  I'm  thinking  about  this  is  I'm  trying  to take  you  on  the  shortest  path. From  knowing  basically  just  calculus and  a  little  bit  of  linear  algebra, to  being  able  to  understand  how systems  like  PT  four  works  remarkably. That's  actually  possible. You  can't  learn  how  to  build a  nuclear  power  plant  in  110  week  quarter. If  you  only  know  calculus, you  can  learn  how  to  build  four  in  110  week  quarter. It's  a  remarkable  thing. It  turns  out  that language  models  are just  a  fancy  instance  of  regression. Like  statistical  regression, we're  going  to  start  off  by  learning  about  regression. If  you  understand  how  regression works  in  the  statistical  sense, then  you  along  the  line, far  along  the  way  to  understanding  how. Language  models  like  PT  four  work. So  let's  talk  about supervised  learning also. This  has  to  be  one  of  the  most  let's  call  it  unusual teaching  situations  I've  ever  had with  that  enormous  construction  going  on  outside. This  is  a  real  UCSD  experience  here. Okay. What's  the  general  definition  of  supervised  learning? You  have  a  data  set  D, it  basically  just  consists  of  pairs. Pairs  of  vectors.  It's  a  set  of  pairs  of  vectors, x,  I,  y,  I. You're  trying  to  learn  to  predict  the  y's. Your  goal  is  to  predict  the  vector  I, given  the  vector  I,  that's  your  goal. Another  name  for  this  type  of  problem  is  regression. You're  trying  to  learn  how  to  predict  why  I  give  an  x. We  can  say  this  in  a  slightly  different  way, which  is  our  goal  is  to  learn a  function  such that  f  of  x, let's  say  approximately  equals. Why  do  I  say  approximately  equals? Because  data  has  noise, you're  never  going  to  be  able  to, or  you  don't  always  at  least  want  to  be able  to  fit  that  noise  exactly. You're  only  going  to  be  able  to  get  an  approximation, usually  to  the  quantity  that  you're  trying  to  predict. Let's  talk  about  one  special  case  of  this, which  is  regression  was  univariate. Univariate  means  just  one  input  variable. So  here's  a  very  simple  sample  dataset. What  does  this  mean?  Means  we  have  three  data  points. X  one  is  equal  to  seven, Y  one  is  equal  to  four, X  two  is  equal  to  three, Y  two  is  equal  to  two. We're  going  to  be  trying  to  predict  the  Y's  from  the  X. Maybe  our  task  is to  Metacritic  scores. This  is  going  to  be  a  sentiment  analysis  problem given  movie  reviews  predict the  Metacritic  scores  number  of occurrences  of the  word  profound. Movie  critics  like  to  use words  like  profound  in  their  movies. To  make  themselves  sound  smarter, we  can  look  at  number  of  occurrences of  a  word  like  profound  in  the  review. Use  that  to  predict  the  Metacritic  score. Probably  if  you  have  a  lot  of  occurrences of  this  word,  it's  a  good  review. Okay,  in  this  case, to  be  the  counts  of the  number  of  occurrences  of  the  word, the  I's  are  going  to  be  the  scores  of  the  movie. This  is  like  the  simplest  type of  sentiment  analysis  that  you  can  do  just based  on  word  frequency,  Word  occurrence. It's  actually  a  very  effective  way to  do  sentiment  analysis. Count  up  a  number  of  different  words in  a  review  or  whatever  it  is, a  tweet,  an  article. Different  types  of  words  are  going  to  be  linked to  something  being  positive. Something  being  negative.  Something  being happy,  something  being  said. We'll  have  here  x  equals  profound. Y  is  equal  to  score. I  don't  know.  Maybe  our  data  looks  something  like  this. It's  a  little  bit  noisy. But  as  we  have more  occurrences  of  this  word,  the  score  goes  up. You  can  have  movies  that  are  not profound,  to  have  a  high  score. Generally,  there's a  relationship  here,  univariate  regression. What  is  multivariate  regression? Multivariate  regression  is  the  type of  regression  that  deep  learning  does. Multivariate  regression  just  means  you have  multiple  input  variables. So  the  input  is  a  number  of  times that links to  twitch and  the  output,  sorry. And  also  let's  say  a  number  of  times, talk  about  energy  drinks. And  then  when  are  we  going  to  predict  from  this? We  have  two  input  variables that  we're  going  to  be  counting  up. We're  doing  surveillance. We  collect  up  someone's  tweets and  we're  going  to  be  doing  an  analysis  on  them. This  is  you  want  to  make  a  lot  of  money. In  a  way  you  can  start  a  company  that  does  things  like this  in  order  to  sell  profiles  of  users  to  advertisers. The  output, let's  say  level  of  interest  in  games, lots  of  advertisers  care  about  questions  like  this. Yeah,  very  practical  application  in  this  case. In  this  case  is  a  vector  x, one  is  equal  to 74y1  is  just  a  scalar, It's  the  level  of  interest,  let's  say  it's  a  ten, like  we're  on  a  ten  point  scale. This,  they  have  twitch  links, they  talk  about  energy  drinks, they're  very  interested  in  games, Our  X's  and  Y's  are  going  to  look  like  this. In  general,  this  is  a  little  bit  harder  to  visualize just  because  it's  not a  two  D  graph  anymore,  it's  a  three  D  thing. I'm  not  going  to  try  to  even  draw. Think  we  see  what's  going  on  here. Any  questions  about  this  so  far? Yeah,  Okay,  look. Full  warning,  full  disclaimer. This  is  not  the  most  exciting  content. The  exciting,  deep  learning  stuff  is going  to  come  later  in  this  course, but  this  is  already  deep  learning. It  turns  out  deep  learning  is  extremely  simple. The  fact  that  GPT  four  can  be  basically  components. We  haven't  quite  gotten  to  them  yet, we're  going  to  get  to  them  in  a  few  minutes. But  basically  built  out  of  components  that we  discovered  like  100,  200  years  ago. I  can  teach  to  all  of  you  in  a  couple  of  lectures. That's,  it's  magic  that  nobody  understands. We  can  build  these  things  of  these  components. I'm  teaching  you  about  the  components. I'm  not  going  to  be  teaching  you  anything about  why  these  things  work. The  reason  I'm  not  going  to  be  teaching  you  anything about  why  these  systems  work  is  that  we  have  no  idea. Every  passing  year  we know  less  and  less  about  why  they  work. When  I  started  teaching  this  course  six  years  ago, probably  six  years  ago, we  thought  that  we  had  some  idea  about why  the  systems  at  that  time  work. There  was  some  mystery. They  worked  better  than  we  thought  that  they  would. But  like,  you  could  give a  handwavy  explanation  and maybe  it  wasn't  so  unsatisfying. But  it's  gotten  pretty  ridiculous  at  this  point, how  far  our  human  understanding has  gotten  from  the  actual  applications. It's  an  apology  for  this  material  being  a  little  bit  dry. And  it's  also  a  justification,  really  is  what  it  is. If  you  want  to  learn  about  the  magic, this  is  what  we  know. Let's  talk  about  binary  classification. I'm  basically  just  telling  you  about different  types  of  regression  problems. Univariate  regression  is  one. Multivariate  regression  is  binary  classification. This  is  another  type  of  regression  problem. So  in  general,  we  have some  number  of input  variables. And  the  special  thing  about  binary  classification, it's  not  the  input  which  can  be  basically  anything. It's  the  output  which  has  to  be  zero  or  one. Maybe  we  have  a  problem  that  looks  like  this. We  want  to  look  at  a  restaurant's  advertising and  classify  whether  it's  a  fast  food  restaurant. Or  we're  going  to  look  at  a  number  of  times, words  like  burger  or  similar  words  occur, number  of  burger  occurrences  in  the  advertising. Let's  say  a  number  of  times,  they  talk  about  fries. We  have  two  input  features,  these  are  count, we're  going  to  look  at  the  advertising  material, count  these  things  up,  maybe  the  menus  to. Then  we're  going  to  have  two  different  categories. The  stars  to  indicate one  category  and  then  we  have  pluses. The  other  category,  probably  the  pluses  are things  plus  will  indicate that  you  are  a  fast  food  restaurant. The  stars  indicate  that  you're  not. We  have  two  classes,  1.0  what  do  we  want  to  do? We  basically  want  to  draw  a  line that  separates  the  two  classes  from  each  other. Many  possible  lines  we  could  draw, here's  a  pretty  good  line  like  that, so  we  want  to  find  the  best  line  to separate  these  things.  That  would  be  the  goal. This  class  has  gotten  actually progressively  more  ridiculous  to  teach  over  the  years. Because  on  the  one  hand, it's  actually  gotten  much  simpler. It  used  to  be  that  there  would  be  all  of these  different  methods  and I'd  have  to  teach  all  these  different  methods. And  I'd  say  at  the  end  of  the  quarter  well, there's  tons  and  tons  of stuff  that  you  haven't  learned  yet. Uh  and  there  will  be stuff  that  you  haven't  learned  yet  after  this  quarter, but  like  the  number  of  methods  that  people  in the  field  actually  use,  it's  shrunk. There's  not  going  to  be  all that  much  more  that's  actually practically  useful  right  now  that  I  won't  be  teaching. But  that's  not  the  main  reason  why  it's  so  ridiculous. It's  like  I'm  teaching  alchemy. It's  very  disturbing  to  me  that  I'm  pretending that  I'm  actually  teaching you  like  scientific  knowledge.  I'm  giving  math. It's  going  to  look  like  a  science  course, except  it's  actually  a  course  about  magic, about  some  stuff  just  happened  after  we put  some  data  in  some  compute  into a  blender  and  we  mixed  it around  and  out  came  the  systems. Yeah,  I  don't  know,  it's  just  a  little  bit  ridiculous. So  keep  that  in  mind  when  you're  watching  me  pretend that  this  math  actually  is  explaining  anything. The  math  is  telling  you  what mechanically  we  did  to  get  here. Okay,  least  squares  regression. Least  squares  regression  is  one  way  of solving  regression  problems.  It's  pretty  close  to. Not  that  far  away  from  what's  actually  done  in  practice. We'll  talk  about  one  type  of lease  squares  regression  as  applied  to  linear  regression. You  could  do  a  squares  in  other  settings  too. We'll  see  how  it's  applied  to  linear  regression. Linear  regression,  what  does  that  mean? In  the  simple  case,  in  the  one  variable  uni  variate  case, you  have  two  variables,  X, which  is  your  single  input  variable, which  is  your  output  variable. You  have  a  bunch  of  points, you  have  a  bunch  of  observations  that  you've  made. It  looks  like  this.  Your  data  is  a  little  bit  noisy. You  generally  notice  as  x  increases,  Y  also  increases. You  want  to  draw  a  line  that  predicts  Y's  given  X. That's  what  the  linear  in  linear  regression  means. It  means  you  want  to  find  a  line. You're  not  going  to  be  trying  to  find any  other  type  of  curve.  Let  me  draw  a  line  here. I  think  intuitively  we  know  what the  best  line  should  look  like. Looks  something  like  that.  It's  okay. Let's  see  if  we  can  draw  a  slightly  better  line  to get  the  point  across  the  line  look  like. Maybe  that's  a  little  bit  better. Let's  put  a  point  there,  okay,  that  looks  better. What  goal  are  we  trying  to  accomplish  with  this  line? What  we're  trying  to  do  is  minimize  the  average, or  total  distance  between the  predicted  points  on  this  line and  the  observed  points. For  a  particular  value  of  x, we  look  at  what  was  predicted  by  the  line. And  then  we  measure  the  distance between  the  line  and  what  was  actually  observed. We  do  that  all  of  the  points, the  dotted  lines  here,  indicate the  distance  between  what was  predicted  and  what  was  observed. We're  going  to  collect  up  all  of  those  distances, sum  them  up,  and  find  the  line  that  minimizes  that  sum. It  corresponds  to  what we  intuitively  think  of  as  a  well  fitting  line. It's  interesting  that  we  visually  see  what the  line  should  look  like  without even  knowing  that  we're  performing  this  calculation. But  that  is  the  calculation  that  we  are  performing, at  least  our  visual  system  is  performing. Let's  formalize  this  a  little  bit. We  have  predictions  that  we're going  to  be  making  given  our  single  input  variable  x. The  predictions  are  going  to  be  a  function, f,  which  is  defined  as  a  line. It's  a  function  and  it's  going  to  be a  function  that  has  two  parameters,  a  and  B. It's  going  to  be  a  x  plus a  is  the  slope,  is  the  intercept. Then  for  each  actual  observed  point, we're  going  to  be  calculating  residuals. A  residual  is  the  actual  observed  point, y  minus  f  of  x. So  the  magnitude  of  this  is the  distance  between  the  prediction  and  what's  observed. Let  me  pause  here  for  1  second. Any  questions?  No. Okay. So  what  does  Lee  squares  regression  do? The  best  line  is  the  one that  minimizes the  sum  of  squared  residuals. That's  a  little  bit  more. There's  a  little  bit  to  say  about  what  that means  to  actually  explain  this. In  other  terms  that  are  a  little  bit  more  precise, we  have  to  introduce  what's  called  a  loss  function. We  actually  saw  loss  functions briefly  in  our  first  lecture. Remember,  the  loss  functions  were  being  used  to  measure how  well  or  how  poorly  language  model  was  predicting. The  next  word  we  saw  there  was this  amazing  relationship  between the  size  of  your  model  and  the  loss  that  it  achieved, or  the  amount  of  data  that  you  gave  to your  model  and  the  loss  that  it  achieved. Well,  you  can  define loss  functions  in  very  simple  situations  like  this. Here,  our  loss  function  in  general, our  loss  function  is  going  to  be  a  measure of  how  bad  your  current  model  is. In  this  case,  we  can  define the  loss  on  a  particular  dataset  D, D  is  equal  to  our  dataset. In  this  case,  the  loss that  a  model  achieves  on  a  dataset  D, let's  actually  just  explain  what's  in  this  dataset. What's  in  the  dataset  is  just  a  sequence of  pairs  of  numbers,  pairs  of  x, and  it's  a  set  of  x,  which  is  a  scalar, which  is  a  single  number, and  Y  I,  which  is  also  just  a  single  number. I'm  not  drawing  a  little  hat  over these  things  because  they're scalars,  they're  not  vectors. Let's  actually  write  slightly  differently. We're  going  to  write  the  loss  achieved  on a  dataset  by  a  particular  parameter  theta. What's  theta? Theta  is  just  another  way  of  writing  down, collecting  up  these  two  coefficients in  our  linear  regression  formula. Here  we're  just  defining  a  line. We're  trying  to  find  a  function  f, where  the  function  is  just  Ax  plus  b. We're  trying  to  learn  what the  correct  value  of  a  and  B  are, if  we  know  a  and  B  are,  that  defines  our  line. I'm  just  saying  that  theta, it's  a  vector  that  just  consists  of  a  and  B, which  is  a  notation  for wrapping  those  two  things  together. The  loss  achieved  on the  dataset  given  a  particular  theta. What's  that  equal  to? It's  equal  to  a  sum  over  our  dataset I  equals  one  to  n.  N  is  the  size  of  the  dataset. We  have  n  different  pairs. In  this  dataset  D,  we're  going  to  take  the  residuals. What's  the  residual?  It's  Y  minus  F  of  X. It's  going  to  be  Y, I  minus  F  of  X. I  square  it  so I  have  the  residual  on  each  different  data  point. I  square  it.  I  sum  that  up.  That's  my  loss. Any  questions? No.  Okay. Yes.  Residual  mean  squared  error. That  is  what  this  is.  It's  not  the  mean, this  is  the  sum,  but  this  is  the  squared  error.  So  yes. Another  term  for  least  squares  regression. I  mean  squared  error  is,  I  guess, a  slight  generalization,  but  this  is basically  mean  squared  error.  That's  correct. We're  taking  the  error  residual  measures  the  error. It's  the  distance  between your  prediction  and  the  actual  outcome. We're  squaring  that  error  and  then  we're  summing  it  up. Taking  a  mean  is  just  taking the  sum  and  then  dividing  by  the  number  of  data  points. But  we're  going  to  be  trying  to  minimize  the  loss, and  so  it  doesn't  matter  whether  you divide  by  N  or  not  to  do  that  minimization. Any  other  questions?  It's  a  good  question. How  many  people  have  purchased  GPT?  Four  subscriptions. Okay. Good  number,  more  review than  you  had  it  on  the  first  day. Those  of  you  who  are  the  holdouts strongly  recommend  it  for  the  sake of  many  things  in  this  class, More  than  strongly  recommend  it, more  than  strongly  recommend  it. Let  me  put  it  another  way. There  are  ways  that  you  could  calculate the  expected  economic  benefit from  subscribing  to  GPT  Four, I'm  not  going  to  tell  you  where those  economic  benefits  come  from. Some  of  them  are  perfectly  okay. Let  me  advertise  some  of  them, which  is  if  you  want  to  start  a  business or  you're  applying  to  jobs, you  seniors,  you're  applying  to  grad  school, this  will  help  you  immensely. And  that's  completely  fine,  right. Economic  benefits  from  getting  a  job  offer, or  at  least  getting  an  interview  offer  versus  not, because  you  were  able  to  automate your  entire  job  application  pipeline and  do  things  in  like  a  super  high  through  point  way, like  apply  to  ten  times  as  many  jobs  as  you  could  before. The  benefits  from  that  far  outweigh  $20  a  month,  okay? So  there's  no  reason  why  you  have  to  only use  this  for  this  one  class, okay?  So  let's  expand  this  term  here. Let's  look  at  this  loss. And  our  goal  is  going  to  be  to actually  use  this  definition of  the  loss  function  which  says, take  all  of  the  errors, sum  them  up,  square  them,  minimize  that  quantity. We're  going  to  actually  use  that  definition in  order  to  find  an  optimal  line. We  want  to  find  the  formula  for  the  optimal  line. And  this  turns  out  to  be  very  straightforward  to do  if  you  know  just  a  little  bit  of  calculus. So  I'll  rewrite  what  we  had  over  there. So  we  have  the  loss  on  the  data  set  given  theta, this  is  basically,  we  have  a  particular  theta. This  theta  we  can  think  of  as a  guess  about  what  the  value  of  A  and  B  are. What's  the  correct  slope  and  what's the  correct  intercept  for  this  line. The  guess  may  be  correct  or  it  may  not  be  correct. This  is  saying  how  well  does that  particular  guess  do  or  how  badly  does  it  do? High  loss  is  bad.  High  loss  means  you have  lots  and  lots  of  errors  that  you're  summing  up. It's  equal  to  the  sum  over  your  entire  data  set of  YI  minus  f  of  xy  squared. What  we're  going  to  do  is  expand  this  definition  of, we're  just  going  to  substitute  in  Ax  plus B  I  equals  one  to  n  Y  I  minus. And  then  what  do  we  do  here? It's  going  to  be  A  x I  minus  b  squared  I  just  substituted. And  what's  the  definition  of?  It's  a  line  with. Okay. What  are  we  going  to  do  now? We  want  to  find the  value  of  a  and  B  that  minimizes  this  formula, that  minimizes  this  expression. How  do  we  do  that  in  general? Yeah,  take  the  derivatives. So  what  can  you  say  a  little  bit  more  about? What  derivatives  are  you  going  to  take? The  gradient  function.  Good.  We're  going to  take  the  gradient  function  and  set  it  equal  to  zero. So  what  is  the  gradient? We're  going  to  be  talking  about the  gradient  a  lot  in  this  class. I'm  very  happy  that  you  mentioned  that  for those  of  us  who  don't  remember  what's  the  gradient, I'm  sorry,  that's  true, but  there's  a  precise  thing  that  we  can  say  here. Yeah,  exactly. We  have  two  variables  here. We  have  A  and  B.  We're  going  to  take the  partial  derivative  of the  loss  function  with respect  to  each  of  these  parameters, and  we're  going  to  collect  them  up  into a  vector.  That's  what  the  gradient  is. We're  going  to  set  that  thing  equal  to  zero. Now  there's  different  ways  we  can  do  this. Just  like  in  terms  of  how  to  do  this  computation, I'm  going  to  set  this  up  in a  particular  way  that  will  make the  computation  a  bit  less,  just  so  I  have  fewer. It'll  just  make  it  a  little  simpler, it's  not  that  much  of  a  big  deal. But  I'm  going  to  introduce  two  new  functions, and  I'm  going  to  redefine our  loss  function  in  terms  of  those  new  functions. Our  first  function  we'll call  takes  a  single  number  and  it  squares  it. I'm  going  to  define  another  function  is  four  arguments. Why  is  it  give  us  back?  It's  going to  give  us  back  the  residual. I  take  x  and  y  are  two  data  points, a  and  B,  the  slope  and  intercept. And  it's  just  going  to  compute  the  residual  from  this. It's  going  to  be  y  minus X  minus  Ax  plus  b.  That  was  the  prediction. We're  going  to  do  y  minus  that  thing. Okay,  Now  we  can  define the  loss  function  in  this  case  as. A  composition  of  functions. It's  going  to  be  h  is  a  function  that  squares  stuff, let  me  wrap  this  thing  in. The  sum,  our  loss  is  the  sum  of  h of  XI  YI  a  B gets  the  residual  squares  it, we  sum  that  up  for  all  the  data  points  in  our  dataset. Because  I've  written  in  this  way, I  can  now  take  the  partial  derivative  of the  loss  function  with  respect  to  a  and B  in  a  nicer  way than  I  would  have  been  able  to,  otherwise. What's  the  partial  derivative  of the  loss  function  with  respect  to  A? How  can  I  define  this given  the  definition  of  the  loss  function? I  have  can  someone tell  me, let's  Yeah. Ignore  all  the  others  because  all  the don't  because  those  the  derivative  of  those  respect. So  that's  totally  correct. But  it's  going  to  turn  out  to  be  the  same  thing. But  I'm  more  thinking  in  terms of  how  do  I  use  this  definition. I  have  my  loss  function  defined  in  terms  of these  two  functions  and  it's  a  function  composition. I  first  do,  then  I  hand the  result  of  that  to  H.  That's  my  loss. How  do  I  use  that  to  take  a  partial  derivative? Yeah,  chain  rule. Chain  rule  is  going  to  be  our  friend, all  of  the  calculus  involved  in deep  learning  is  just repeated  application  of  the  chain  rule. Okay.  So  I  use  the  chain  rule.  Good. What  do  I  do?  What  does  that  mean  here? Yeah,  okay,  great. I  multiply  the  two  partial  derivatives. We,  there's  one  more  part here  which  is  I  have  a  sum,  right? So  it's  going  to  be,  I'm taking  the  partial  derivative  of  a  sum. How  do  I  take  the  partial  derivative  of  a  sum? And  someone  remind  me,  yeah, I  just  put  it  inside  the  summation. It's  the  sum  from  I  equals  one  to  n. We'll  do  this  in  a  couple  of  steps. So  it's  going  to  be  the  partial derivative  with  respect  to  a  of  this  whole  thing. Okay, Now  let's  actually just  talk  about  this  term  here  for  a  second. So  we  have  partial  derivative  with respect  to  a  h  of  of  I  YI. I  use  the  chain  rule. So  what  is  the  chain  rule  tell  me  to  do. It's  going  to  be  the  partial derivative  with  respect  to A  times  partial  derivative. Let  me  fix  that. It's  h  with  respect  to  times partial  derivative  of  g  with  respect  to  a. Let  me  make  sure  that  my  a's  and s  here  are  very  distinct  from  each  other. Okay?  What  am  I  doing? I'm  trying  to  see  how  does  this function  change  when  I  change. And  then  I'm  going  to  see  how  changes  when  I  change  a, That's  what  the  chain  rule  is  telling  us. And  I  multiply  those  two  quantities  together. Let's  do  each  of  these  things  at  once, or  I  should  say  separately  from  each  other. What's  the  partial  derivative  of  H  with  respect to what  does  do when  it  gets  it  squares  it. This  is  equal  to  two. Okay?  And  then  what's the  partial  derivative  with  respect  to  a? We  actually  have  to  look  at  this  thing  here. What  is  the  definition  of  it's? We're  taking  the  partial  derivative of  this  with  respect  to  A. What  do  we  get?  It's  minus  x,  minus  x. Let's  be  a  little  bit  more  precise  here. Okay,  then  we  can  return  to  this  term, the  partial  derivative  of  L  with  respect  to  A. It's  equal  to  a  sum  from  I  equals  one  to  n. What  is  it  going  to  be  negative? It's  going  to  be  times  this  term, so  it's  going  to  be  negative  x  multiplied by  g.  What's  g  equal  to? G  is  equal  to  this,  two  times  g.  It's  going  to  be two  times y  minus  Ax  minus  B. We  can  simplify  this  a  little  bit. This  is  equal  to  two  times  the  sum  from  I equals  one  to  n  of  A, xi  squared  minus  x, y  plus  x  I. Okay,  I'm  going  to do  exactly  the  same  thing  now  for the  partial  derivative  with  respect  to  B. And  remember  why  I'm  doing  all  of  this. I'm  computing  the  partial derivative  with  respect  to  a  and  B. Because  I  want  to  find  the  optimal  values  of  a  and  B, I'm  going  to  take  the  partial  derivatives, set  them  equal  to  zero, and  then  solve  for  a  and  B. By  the  way,  there's  another  part  of the  lawyers  I  didn't  mention, it  turned  out  that  when  I  hired  the  lawyer, like  I  had  a  first  meeting  with  him, everything  sounded  great  for  all  that  I  knew. And  then  he  asked  for  a  ridiculous  amount  of  money, and  I  gave  him  the  money. He  had  my  money. And  it  was  only  after  he  had  had my  money  for  a  few  weeks and  done,  who  knows  what,  with  it, that  I  found  out  that  he  had  made  a  major  mistake. I  fired  him,  but  I  also  wanted  my  money  back. I  talked  to  GPT four  about  how  I  should  get  my  money  back. Four  gave  me  some  advice. Basically,  it  wrote  an  e  mail  for  me. It's  a  little  subtle. You  have  to  do  a  dance  in  these  situations  because  you don't  want  to  actually  accuse  the  lawyer  of  misconduct. Because  if  you  do,  then  they're  going  to  be worried  about  a  lawsuit  themselves. You  want  your  money  back.  You  want  to  be a  little  bit  aggressive  about  it, but  you  also  don't  want  to  say  anything where  if  the  lawyer  concedes  to  you, he's  admitting  that  he  did  something  wrong  and then  that  exposes  him  to  legal  exposure. Basically  four,  walked  me  through  all  of  these  issues. Crafted  an  e  mail,  yesterday, I  found  out  that  I'm  getting  all  of  my  money  back. Thank  you.  Yeah,  it's  good. Gp  four  also  reminded  me  about  the  human  factor  here, which  is  that  you  don't  want  to  make  him  feel humiliated  for  having  made  this  mistake. That  these  emotional  factors  can  also influence  whether  someone  gives  you  back  your  money. Let's  do  this  for  partial  derivative. Of  L  with  respect  to.  This  is  equal  to. We're  going  to  apply  the  chain  rule  again. We're  going  to  do  the  chain  rule  in exactly  the  way  that  we  did  down  there. This  is  equal  sum  from  I  equals  one  to  n, partial  derivative  of  g  with  respect  to, times  partial  derivative  of  h  with  respect  to. We're  seeing  how  much  the  outer  function  changes with  respect  to  the  inner  function, how  much  the  inner  function  changes  with  respect  to  B. Multiplying  those  two  things together  can  just  do  a  little  bit  of  math  here. And  what  we're  going  to  end  up  getting, just  skipping  a  couple  of  steps. It's  basically  the  same  thing  that  we  did  before. It's  going  to  be  negative  one  times  two  times Y  I  minus  Ax  minus  b. What's  that  equal  to?  It's  equal to  two  times  the  sum  equals one  to  n  of  x  I  minus  Y  I  plus  b. What  we're  going  to  do  now  now  we  have  definitions. We've  solved  for  the  partial  derivative of  the  loss  function  with respect  to  B  and  with  respect  to  a. We're  going  to  set  those  two  quantities  equal  to  zero. L  D  is  equal  to  zero, DLD  B  is  equal  to  zero. Now  we're  going  to  solve  for  A  and  B  given  this. So  let's  start  from  zero. Is  equal  to  the  partial  derivative of  L  with  respect  to  A. Our  definition,  what  we  found  over  there, which  is  two  times  the  sum  from  I  equals one  to  n  of  x  I  squared. We're  going  to  separate  this  into  a  few  different  sums now  in  order  to  simplify  things  a  little  bit. So  this  is  going  to  be, let  me  say  this  another  way  we  can  get  rid  of  the  two. Here,  the  two  is  not  doing  anything. We  can  just  divide  out  by  the  two. This  implies  that  zero  is  equal to  sum  from  I  equals  one  to  n of  a  xy  squared minus  sum  from  I  equals  one  to  n  of  x, y  plus  sum  from  I equals  one  to  n  of  x  I. Let  me  introduce  a  little  bit  of  notation  here, which  is  I'm  going  to  define just  the  average  value  of  x  as  X  bar. X  bar  is  equal  to  one  over  n  times  the  sum  from  I  equals one  to  n  of  the  x  I.  I sum  up  all  of  the  xs  I divide  by  n,  that's  just  the  average. I'm  calling  that  x  bar.  I  can then  substitute  an  x  bar  over  here. Why  is  that?  If  I  multiply  by  n, let's  just  make  that  clear. Say  n  times  the  sum  I  equals  one  to  n  I. That's  equal  to  n, sorry, let  me,  let  me  say  this  a  slightly  different  way. This  is  equal  to  n  times  x  bar  times,  okay? So  I'm  going  to  be  using  that  relationship  here. What  do  we  get?  What  we  get is  I'm  going  to  replace  this  term with  n  x  n  x  bar  B.  I'm  going  to  move  that, or  I'm  going  to  move  these  terms  to  the  other  side. What  we  then  find  is  that  x,  that  term  over  there, is  equal  to  the  sum  from  I  equals one  to  n  of  x  y  I  minus  the  sum  from  I  equals  one  to  n. Of  A  I  squared. Now  I'm  going  to  set  the  partial  derivative with  respect  to  this  is  two times  some  from  I  equals  one  to  n  of  x  minus  y  plus, that's  just  what  we  over  here, repeating  the  definition  that  we  found  for a  partial  derivative  of  the  loss  with  respect  to  B. Let's  just  expand  this  out  a  little  bit. This  is  equal  to  two  times  A  and  x  bar  minus  and  y  bar. I'm  defining  the  average  value  of  y  in  basically the  same  way  I  define  the  average  value  of  x.  I'm skipping  a  few  steps  here because  I'm  assuming  that we  can  just  expand  out  this  stuff  if  you, if  you  want  to  do  this  on  your  own. What  does  this  imply  when  we  shift  things  around? This  implies  that  n  is  equal  to  n  y  bar  n  times the  average  value  of  y  minus A  times  n  times  the  average  value  of  x. Now  I'm  going  to  solve  for,  now  I actually  have  a  solution  for  in  terms of  a  Y  bar  minus  X  bar. This  is  a  somewhat  cleaner  definition  of  yes. Where? Here?  No,  because  I  got  rid  of the  two  because  this  whole  thing  is  set  to  zero,  right? So  what  I'm  doing  here  is  I'm,  you  know, I'm  solving  for  A  and  B, setting  this  thing  equal  to  equal  to  zero  so  I can  get  rid  of  any  constant  factors  that  are  in  front. Good  question.  Thank  you  for  asking  that. Any  other  questions?  Yeah,  Second. Yes,  you're  correct.  Thank  you.  Thank  you. Yes.  Okay.  For  this  next  line here  sign,  you  mean  here? Well,  right.  But  I  kept  sorry. Okay.  So  I  kept  this  on this  side  and  then  I  moved  these two  terms  to  the  other  side. Yeah.  Great  question.  Thank  you. Yeah,  the  signs  are  a  real  pain. Here.  Look,  look,  here's  the  nice  thing, we  never  have  to  do  math  again,  right? Yeah,  yes I  would. Is  where  we  compute  the  residuals. Says  here's  your  predictions, here's  what  actually  happened. Compute  the  distance  between  them  or  the  difference. And  then  H  says  square  that  difference. Why  do  we  square  it?  Why  do  we define  this  function  to  square  things? It's  the  residuals  will  be  positive. The  diferente,  what's  predicted and  what  actually  happened  will  be  positive. Sometimes  it  will  be  negative. We  actually  care  about  is  like  the  absolute  magnitude. And  squaring  is  one  way  to  get  that  Good  question. Yes,  it  could  be  the  absolute  value, but  then  if  it's the  absolute  value  we  can't  differentiate. The  simplest  answer  to  why  do  we square  is  that  it's  mathematically  convenient. There  are  other  reasons  to squaring  has  a  bunch  of  nice  interpretations  to  it, but  simplest  answer  for  us  right  now  is  just  that, it  makes  the  math  easy. Any  other  questions?  Okay,  good. Thank  you  for  these  questions. Okay,  so  we  have defined  in  terms  of  y  bar  and  x  bar,  which  is  good. Those  are  quantities  that  are  given  to  S  bar  data. X  bar  is  just  the  average  value  of  the  xs  in  our  dataset. Y  bar  is  just  the  average  values of  the  y's  in  our  dataset. Those  are  both  things  that  we  can  easily  measure. A  is  not  so  good because  that's  a  parameter  that  we  want  to  know. What  we're  going  to  do  is  we  have this  formula  here  for  B. We're  going  to  plug  this  formula into  this  expression  here, which  we  got  when  we  set  the  partial  derivative  of the  loss  with  respect  to  a  equal  to  zero. Let's  do  that  now. We  have  Y  bar  minus A  times  n  X  bar.  How  did  I  get  that? I  took  the  value  of  B  here, which  is  Y  minus  A  X  bar, and  I  substituted  in  here. I'm  just  going  to  do  a  substitution  of this  into  this  expression  wherever  I  see. What's  that  equal  to?  It's  equal to  this  thing  on  this  side  here. Okay,  I'm  just  going  to  rearrange  some  terms. Just  distribute  this  multiplication  here. So  I  get  y  bar  times  x  bar minus  a  and  x  bar  squared. It's  equal  to  the  things  on  this  side. What  can  I  do  now? Remember  what  my  goal  is. The  x  bars  and  the  y  bars, both  of  those  things  are  just  the average  values  from  my  data. I  can  easily  compute  those. I'm  interested  in  the  value  of  a, so  how  do  I  get  the  value  of  a? Do  you  see  a  strategy?  I  see  a  strategy.  What  can  we  do? Yeah,  S  that's  certainly  true.  Yes. That's  going  to  be  one  of  the  things  that  we  do. Yeah.  Terms. That's  all  we're  going  to  do  Exactly. It's  just  there's  nothing  very  exciting  going  on. It's  just  I'm  going  to  collect up  all  the  terms  with  the  A.  I'm  going, I'm  going  to  pull  the  a  out  and  then  divide by  that  thing.  What  do  I  have? Y  bar  times  n  x  bar minus  I  equals  one  to  n  x  I,  y  I. So  this  is  equal  to  A  x  bar  squared  minus A  I  equals  one  to  n  of  x  I  squared. I'm  going  to  pull  out, I'm  going  to  pull  out  the  A  here. I  have  A  times  n  x  bar  squared minus  sum  from  I  equals  one  to  n  x  I  squared. This  is  equal  to  y  bar  n  x  bar  minus  that  product. So  I  get,  I  get  a  formula  for  A. Now,  I  just  did  this  thing  by  this  thing, so  it's  going  to  be  y  bar n  x  bar  minus  divided  by. Okay?  So  we  found  a.  How  do  we  find  B? I  found  a  value  for  a,  right? I  can,  I  can  just  look  at  my  data. The  formula  is  a  little  complicated. I  can  just  look  at  my  data,  compute  this  formula. Now  I  have  a  value  of  the  optimal  slope. This  is  the  best  slope  that  I  can  find  for a  best  fitting  line  for  my  data  set. Okay,  best  value  of  A. What  do  I  do  to  find  the  best  value  of  B? What  did  I  find  here  that  is  equal  to y  hat  minus  ax  hat  or  bar,  I  should  say. What  I  can  do  in  that  case  is just  substitute  in  the  optimum  value  of a  I  found,  then  we're  done. We  found  the  optimal  slope  and  intercept  for  this  line. That's  a  deep  learning  is  trying  to  do. It's  trying  to  find  the  best  value  of  a  and  B  and some  other  parameters  are  basically things  that  are  doing  something  similar  to A  and  B  in  a  much  more  complicated  setting. But  it's  really,  it's  just  linear  regression, a  little  bit  of  math  applied  to  much, much  bigger  data  sets. It's  all  deep  learning  is. Let's  end  here.  I'll  see  everyone  on  Thursday.
