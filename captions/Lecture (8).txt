All  right,  let's  start  any  questions  before  we  begin. No.  I  was  promised some  questions  at  the  beginning  of  this  lecture. There  were  people  here who  told  me  they  would  ask  questions. But  if  you're  not  feeling  in  the  mood  today,  that's  okay. I  just  won't  answer  those  questions. Yes,  Chachi  PPI.  Okay.  Thank  you. I  will  get  to  that  in  one  moment. So  that  was  one  question, there  was  another  set  of  questions  that people  wanted  to  ask  me  the  end  of  last. But  yes. Yeah,  go  ahead.  Yeah. Do  I  think  these  models  are  moral  or  ethical? Good  question.  Let's  turn off  the  recording  of  this  lecture. Things  that  I  had  planned  today. Thank  you  for  asking the  questions  that  started  all  of  this. And  welcome  back  everyone  who's  watching  on  your  podcast. You  must  wonder  what  happened. I'm  not  going  to  tell  you,  I want  to  do  a  few  things  before  we start  the  main  materials. The  first  is  a  strategies  for  prompting  these  models. Because  I've  talked  to  many  great  students in  the  class  now  about  this  issue. I  believe  that  people  have the  courage  do  what's needed  to  get  the  most  out  of  these  models. Why  is  it  the  courage is  treat  these  models  like  a  person? I'm  not  saying  they  are,  as  I  say, to  get  the  most  out  of  them, you  need  to  treat  them  like  a  person.  It's  a  crazy  thing. Let  me  show  you  a  very  practical  application  of this  bug  the  clown. Someone  in  class  asking  me  about  this. I  don't  know  who  by  the  clown  is, but  apparently  G  four thinks  they  have  the  wrong  hair  color. Interesting.  Let's  see. Okay,  here  we  go. So  this  was  a  very  long  conversation. You  can  see  that  I  had  with  GT  42  days  ago. The  context  is  that  I  was writing  a  paper  that  I  was  submitting  to  a  conference. Now  I  had  already  actually  used T  four  to  write  the  first  part  of  the  paper. So  here's  the  first  part  of  the  paper I'm  submitting  to  an  LP  conference. Await  further  instructions. I  just  want  to  show  it.  I  don't need  anything  from  you  yet. Just  here's  what  I've  written. I  wanted  to  understand  the  paper  like  up  to that  point  so  that  I  can  then  use that  context  in  order  to  help  me. And  providing  context  is  one  of the  most  important  things  that  you  can do  when  you're  using  these  models. Like  it  needs  information, it's  not  omniscient,  it  doesn't  know  everything. If  you're  writing  a  paper, show  it  what  you  have  so  far  or  tell  it  your  idea  so  far. So  I'm  doing  a  few  things  here. I'm  giving  it  the  context like  here's  what  the  paper  is  about, here's  what  happens  in  the  paper. I'm  also  showing  it  an  example of  a  writing  style  that  I  like. I  like  the  paper  as  it  was  written  up  to  this  point, it  doesn't  know  GBD  four  contains  within it  from  Ralph  Odo, Emerson,  the  other  guy  who's the  other  19th  century  poet might  be  I  contain  multitudes. Gp  four  contains  multitudes. It  has  everyone  who's  ever  existed, basically  within  it,  the  ability to  simulate  them.  Not  quite. That's  a  good  first  start  for  thinking  about  it. When  you  talk  to  GP, ask  it,  write  an  e  mail  for  me,  write  a  paper  for  me. It  doesn't  know  which  of  those  characters  to  call  up. I'm  telling  it  right  now,  Here's the  character  that  I  want  you  to  call  up. It's  the  person  that  would  write  this  paper. Okay,  I  pasted  in  this  stuff. It's  a  pretty  long  piece  of  text. I  give  it.  It's  the  intro  to  my  paper. Okay.  Okay. It  set  text  appears  to  be the  introduction  literature  review  of  a  research  paper focused  on  this  good  summary. Now  it  says  before  offering  specific  feedback, it  would  be  helpful  to  know the  specific  instructions  you  have. Just  tell  you  I'd  like  to  improve  the  next  section. Here's  the  first  paragraph  I  give  it that  I  actually  did  not  like  this  at  all. Let's  see  why  I  didn't  like  it and  this  is  why  I  mean  that  the  model contains  now  the  model  is  writing  in  a  bragging  way. I  don't  like  writing  papers  like  that. Or  traditional  IR  systems  thrive  on the  symbiotic  relationship  between  two  entities. It's  like,  this  is  ridiculous. Here's  what  I  don't  like  about  this. Tone  it  down,  That's  why  I  told  it  to  do. Tone  it  down.  This  is  for  a  computer  science  publication, understood  for  a  computer  science  audience. Clarity  and  conciseness,  along  with a  more  straightforward  style,  are  often  appreciated. Here's  a  more  toned  down  version. Let's  see.  Great. I  give  it  some  explicit  feedback. I  tell  it  like,  yeah,  good,  I  like  that. Here's  my  next  section  and  then  I  paste  in  the  section. Okay,  interesting.  So  I  said, I'm  pretty  happy  with  this  previous  section. I'd  like  you  to  help  me  cut  down subsequent  sections  which  were  written  by  my  students. So  I  give  it  some  text. So  here's  a  then  it's responding  with  its  edits  to  that  text. I  ask  it  to  do,  I'm  giving  it  some  feedback. It  contains  some  redundant  information. So  I  tell  it,  take  out  the  redundant  information. Like  you're  giving  an  intro here.  I  don't  need  that  intro. I'm  actually  just  telling  it  what  I  want, what  was  wrong  with  it, what  it  did,  and  what  I  want  from  it. Okay,  so  the. I  didn't  like  that  direct  simplify. So  let's  see,  what  was  the  problem  with  it,  okay? The  unrealistic  parity  between  queries  and documents  is  not  reflective  of  real  world  interactions. I  mean,  it's  not  like  the  worst  thing  ever, but  the  language  is  too  complicated. I  don't  need  to  talk  about,  you can  say  it  does  not  reflect  real  world  interaction. It's  reflective  of  to  disrupt this  superficial  mimicry  and  encourage  to understand  deeper  semantic  relationships. It's  too  fancy  the  language. I  don't  want  that.  I  tell  it  more  direct, simplify,  I  give  it  very  simple  instructions. I  just  tell,  here's  why  I  don't like  then  I  guess  I  didn't  like  that  either. I  rewrote  it  myself  at  that  point  and  I  said, here's  what  I  actually  wrote. I'm  providing,  this  is  feedback regarding  the  type  of  writing  that  I  like. Await  further  instructions. I  just  give  it  the  text  that  I'm  telling  it  that  I  like. Let's  see  what  happens  then.  The  model, it's  very  sycophantic. It  tells  you  everything  that  you  do  is  great. I'm  not  going  to  take  that  too  seriously. It's  feedback  there.  Moving  forward, I'll  use  your  text  as  a  guideline  for  the  tone,  style, and  level  of  detail  appropriate  for  your  audience. I  pasted  in  another  section  here, rewrites,  I  don't  like  navigate. Pay  attention  to  what  I  wrote  above. You  don't  need  to  include  all  the  content. Okay,  good  look. I  eventually  got  to  a  rewrite that  I  liked  and  I  gave  it  instructions  about  that. This  is  how  I  use  this, this  is  how  I  use  this  model. And  it's  not  totally  straightforward,  right? It's  just  like  it,  it's  not  a  magic  box  yet, it  can't  read  my  mind. I  have  to  tell  it,  what  do  I  want  from  it? And  these  are  like,  look, if  I  had  a  student  who  was  infinitely patient  and  like  I  wasn't  worried  about  insulting, basically  this  is  how  I  would  talk  to  that  student. It's  like  a  very  intelligent  student, but  like  who  doesn't  know  yet  how  to write  a  paper  in  the  way  that  I  want. That's  what  I'm  telling  this  model  how  to  do, and  eventually  I'm  guiding  it. Here's  what  I  want  from  you. And  saved  me  a  life  time. Something  that  would  have taken  me  4  hours,  maybe.  It  took  me  two. Yeah. Yeah,  that's  a  great  question.  You  have  to  use  what's called  the  system  prompt  if you  wanted  to  do  something  like  that. So  let  me  get  to  that  right  now. Actually,  let  me  get  related  issues. Any  other  questions  about  this? Again,  the  high  level  idea here  is  it's  not just  about  how  to  edit  your  papers,  right? This  is  about  how  do  you  talk  to  these  systems? Just  give  them  very,  very  explicit feedback  about  what  you  liked  and  what  you  didn't. Yes,  it  can  start to  trail  off  after  a  certain  amount  of  time. It  depends  on  how  to, how  many  words  in  you  are. My  hunch  is  that  my  just  feeling  from talking  to  it  is  within  the  first 10,000  words  of  the  discussion, has  a  very  good  memory  and  things  start  to degrade  probably  a  little  bit  beyond  that. Yeah,  I  think  images  also  affect  that. Try  to  play  a  game  of  foo, it  took  way  less  than  10,000  words  forgetting  stuff. But  I  was  great, that's  a  great  observation. Remember  I  told  you  last  time, images  are  just  basically  transformed  into a  special  type  of  word  In  these  models, the  number  of  words  corresponding  to  a  particular, we  don't  know  the  details,  but  it  might  be  large. I'm  not  going  to  give  a  ballpark  number, it  might  be  a  large  number. It  just  takes  up,  the  models  only  have  a  finite  memory, short  term  memory,  and  it's  going  to take  up  a  lot  of  that  short  term  memory. Very  interesting  observation. Okay,  let's  talk  about  the  final  project. I've  gotten  a  lot  of  questions  about  this. The  goal  I've  been  calling  an  AI  tutor. You  may  think  one  thing  when  I say  that  what  I  really  mean  is any  product  that  would help  the  instructor  or  the  students, let's  say  help  the  students in  the  way  that  the  instructor would  want  are  hoping. Previously  we  now, I  think  this  class,  it's  a  little  bit  recursive. I  don't  know  how  to  deal  with  that. It  could  be.  Yeah,  yeah, yeah,  yeah.  Don't  overthink  it. Don't  overthink  it.  Good  question.  Okay. No,  I'd  like  to  hit  a  fixed  point  actually  with  this  one. So  this  is  going  to  be  like  the  final  one and  we  won't  have  to  update  the  class  ever  again. I  think  that  that's  okay. So  anything  that  would  help people  think  about  it  that  way, what  could  that  it  could include  something  that  helps  me  with  grading, that  would  be  great,  like  auto  graders. Auto  graders,  as  they  exist  now, they're  extremely  inflexible. They  break  all  the  time, something  that  is  like GPT  four  that's  helping  with  auto  grading  could  be  great. Actually,  if  you  were  to  go  that  route, you'd  actually  have  to  build  something  that works  and  then  also  demonstrate  that  it  works, which  may  not  be  that  easy. Does  it  work  90%  of  the  time? That's  not  a  useful  auto  grader. 10%  of  errors  means  I  have  to go  through  every  problem  and  check  for  errors. That's  something  to  keep  in  mind. The  second,  don't  train any  models,  use  the  EPI. The  goal  of  this  is  not  to  get  you to  train  your  own  summarization  system  or some  other  system  that  will  help  with the  tutor  because  it  won't  work. Gpt  four  was  trained  with  a  $100,000,000  budget. You  will  have  a  budget  of  $10  You're  not  going  to  build something  that  works  this  thing  that  already  exists. I  want  something  practical that  can  actually  be  used  here. What  is  the  GP  four  API? It's  a  way  to  call  GPT  four  outside  of  the  chat  app. Let's,  we'll  talk  a  little  bit  about  the  structure  there. Now  one  thing  I  want  to  mention is  this  costs  money.  It's  very  cheap. It's  around  $0.02  per  1,000  words  to  use  it. But  I  don't  want  to  make  all  of  you  spend  money. So  we're  going  to  be  getting  you  access  to  the  API. I  have  to  figure  out  some  issues,  the  logistics  of  that. But  you  will  have  access  to  the  API  if  you want  to  just  play  around  with  the  API  right  now. You  do  need  a  credit  card, but  you  could  spend  $1 playing  around  with  it  in  the  initial  stages. You'll  be  able  to  still  get  a  lot  of mileage  out  of  it  with  that  dollar? Yes,  definitely  not  every  month. It  may  be  the  case  that  when you  subscribe,  you'll  get  free  credit. When  you  enter  it  for  the  first  time, you'll  get  free  credits. But  definitely  not  every  month. It's  like  maybe  a  one  time  thing. So  if  you  have  those  three  credits,  great. Please  use  those  three  credits. If  you  don't,  then  we'll  be  getting  you  access. I  strongly  recommend  that  you  play  around  with  this. Okay.  How  can  you  learn  how  to  use  the  four  PI? We're  not  going  to  be  teaching  you  in  class. Can  anyone  take  a  guess  about  how  I  would recommend  learning  about  four  API? Okay?  Yes,  no,  no, don't  read  the  documentation. Yeah.  Okay.  Either  four knows  about  how  the  API  works,  in  which  case,  great. It  may  not  because  it  may be  outside  of  its  training  data. If  it  doesn't,  I  would  go  to  the  documentation, copy  and  paste  it  into  four  and  get  some  examples. Yeah,  it's  a  little  bit,  they've  dumbed  it  down. I  find  the  Bing  version  almost unusable.  I  don't  know  about  you. You  cannot  talk  to  the  Bing  version the  same  way  that  I  talked to  four  in  that  demo. If  you  tie  it  to  the  Bing  version,  they're  like, sorry,  I'm  not  going  to  talk  to  you  anymore. It's  to  do  with  the  RLHF  that  they  did. They  basically  Liobottomized  the  Bing  version. Okay.  Any  other  questions  about  that? Let's  talk  about  the  API  just  for  1  second. There's  a  few  interesting  things  about the  API  that  you  get  access  to. So,  there  are  three  types  of  fields  in  the  API. So  when  you're  sending  information  to the  API  and  receiving  information  back, there's  three  relevant  fields. There's  the  system  prompt, there's  the  user  prompt, there  is  the  assistant  prompt  or  assistant  response. Let's  call.  I  don't  know,  I don't  remember  the  exact  name. It's  basically  the  assistant  response. The  system  prompt  is  somewhere  that  you  can  place high  level  instructions  that  you want  to  persist  throughout  the  entire  chat. Here's  where  I  would  say  you  are  a  tutor. Your  job  is  to  hold  office  hours  for students  for  this  class,  blah,  blah,  blah. You  give  it  detailed  detailed  high  level  instructions about  its  overall  goal. Those  system  prompt  instructions will  be  available  to  the  model. It  will  be  invisible  to  the  other  users, but  it  will  be  available  to the  model  for  as  long  as  the  chat  is  happening. The  user  prompt  two  uses  for  the  user  prompt. This  is  where  you  inject  responses  from  the  users. The  user  tells  you  something, that's  where  the  set, then  it  will  get  sent  back  to  the  chat  app  and then  the  app  process  it. There's  another  interesting  feature here  for  the  user  prompt, which  is  that  you  can  also  put additional  instructions  side  of  the  user  product. Let's  say  that  a  student  is asking  a  question  about  one  part  of  the  course. You  have  a  textbook.  There's  a  bunch of  free  textbooks  in  this  area. Let's  say  you  have  a  textbook. You  can  look  up  a  relevant  section  of the  textbook  past  in that  section  of  the  textbook  into  the  user  product. You  can  say,  hey, GPT,  here  we're  pasting  in  this  section  of  the  textbook, Don't  tell  the  student  about  this, You  don't  need  to  tell  a  student  about  this  anyway. But  here's  the  context  for  answering  their  question. Then  the  student  asks  the  question, then  the  assistant  can  look  up  that  part  of the  textbook  when  it's  answering  the  question. Basically,  when  you're  holding  discussions, you  can  inject  additional  context  into  the  user  problems. The  response  is  where  you're  going  to  be seeing  the  assistant  giving  you  more, giving  responses  to  what  the  students  said. What  I  mean  is  that  we  need  to  think  about  takeaway  here. You're  going  to  be  using  the  API  to  build  a  product. A  product  includes  a  user  interface. A  product  is  designed  to  solve  a  particular  function. I  would  say  the  most  important  thing that  you  need  to  decide  on  is  like, who  am  I  serving? Who  are  my  products  serving? Is  the  teacher  or  is  it  the  student? Who's  the  customer  Am I  trying  to  accomplish  or  why  am I  trying  to  help  the  customer  to  accomplish? Those  are  the  two  most  important  questions. Then  when  you  decide  on  that, you're  going  to  use  the  API  in  some  way  and  you're  going to  do  something  clever  involving these  prompts  where  you're  going  to  be  injecting. I  think  the  thing  that  makes your  app  more  than  just  the  default, chachBTpp,  is  how  you  inject information  into  these  prompts in  the  right  way  and  at  the  right  time. There  are  different  types  of  apps  you  might  build. Something  that  you  might  find  useful is  something  called  Stream  Let. This  is  a  very  easy  way  to  build  chat  apps. Gp  four  knows  all  about  stream,  honestly. There's  no  reason  for  you  to  write  a  single  line of  code  by  yourselves  for  this  project. I'm  not  expecting  you  to,  I  don't  want  you  to. What  I  want  at  the  end  is  something  that's  really  good. I  don't  care  how  you  got  there, as  long  as  you  have  to  cite  your  sources. But  that's  the  only  constraint. The  reason  that's  the  only  constraint  is because  I  mentioned  this  on  the  first  day  of  class, but  I'm  part  of  a  group  on  campus  that's actually  building  AI  tutors  for  classes  on  campus. I  want  to  get  for  those  classes. We  don't  know  what  we're  building  yet. We  have  particular  ideas. But  like  I  want  more  ideas, I  want  you  to  give  me  more  ideas. And  I  want  to  actually  use  what  you build  in  that  context  for  this  class, or  maybe  for  other  classes. I  want  something  that  works. You  should  take  no  pride  in  writing your  own  code, okay? Any  questions,  You'll  get  credit, of  course,  for  anything  that  we  do  that  uses  your  work. I  just  want  to  say  you  will  of  course  get  credit. Okay. So,  well,  I'll  be  sending  out a  more  sort  of  formal announcement  about  all  of  this  stuff. But  I  wanted  to,  I've  been  getting  lots  of  questions, good  questions  about  what  exactly  this  project  should  be. I  hope  this  is  clarifying  things  a  little  bit. Okay, so  last  class we  finished  off  Stochastic  Gradient  Descent. This  class  will  be  talking  about the  multi  layer  perceptron. Now  the  multi  layer  perceptron. It's  an  architecture,  it's our  first  deep  learning  architecture. It  has  a  very  funny  history. It  is  the  very  first  deep  learning  architecture. It  was  invented  in  like  the  1940s. Now  what  happened  after  that  is  a  bunch of  people  invented  all  these  other  architectures. And  what's  happening  in  the  field right  now  is  the  entire  field is  converging  on  this  as  basically  a  single  architecture. If  you  look  at  the  history  of the  last  five  years  or  ten  years  in  deep  learning, it's  the  entire  field  realizing,  oh, we  should  just  be  using  multi  layer  perceptron. Let's  learn  about  multi  layer  perceptron. Uh,  extremely  simple. Let  me  give  a  high  level  motivation for  using  the  multi  layer  perceptron. Imagine  I  have  a  binary  classification  problem. Let's  start  out  with  one  that  looks  like  this. I  have  a  positive  X  is, and  a  negative  class,  the  O's. I  want  to  draw  a  binary, I  want  to  build  a  binary  classifier  for  these  things. Well,  in  this  case  it's  a  easy  binary  classifier. I  can  draw  a  decision  boundary  that  looks  like  this, that  corresponds  to  a  normal  line  that  looks  like  that. Basically,  what  this  line  represents, we  saw  this  in  the  context  of  logistic  regression, is  that  as  you  go  more  in  this  direction, you're  more  likely  to  be  an  X. Logistic  regression  is  great. Why  don't  we  just  use logistic  regression  for  every binary  classification  problem? Why  don't  I  just  draw  like  I  have a  binary  classification  problem,  I  have  Xs  and  Os. I  just  try  to  draw a  decision  boundary  like a  single  line  between  the  Xs  and  Os. Yeah,  what  does  that  mean? What  if  the  decision  boundary  one. Okay,  What  if  the  optimal  one  is  a  curve? So  that's  correct. Can  you  say  there's  something stronger  that  we  can  say  than, what  if  the  optimal  one  is  a  curve?  How  do  we  program? No,  but  there's  a  stronger, I'd  say  like  problem  that  we  can  encounter. It's  a  good,  it's  a  good  observation. Yeah,  he fantastic,  let's  do  that. Let's  do  exactly  what  you  just  suggested. Had  you  seen  this  before?  You,  had you  seen  this  example  before? No.  Good,  great  observation. Okay,  what  if  we  have  a  problem  that  looks  like  this? This  is  called  the  X  or  problem. Our  positives  are  over  here, our  negatives  are  over  here. There's  no  line  that  separates  them. The  reason  it's  stronger  than  what you  were  saying  before  is that  it's  not  just  that  the  optimal  curve  is  not  a  line, it's  that  there's  no  line  that  works  in  general. By  default,  any  problem  that  we have  is  going  to  look  like  this. The  way  that  we  can  think  about  deep  learning, all  of  deep  learning  is  that  it's a  way  to  transform  problems  that  are fundamentally  like  this  in  the  sense  that  there's no  linear  decision  boundary into  problems  where  there  is  a  linear  decision  boundary. In  this  case,  we're  going  to  be trying  to  figure  out  a  way  to  transform this  space  in  such  a  way that  what  we  get  looks  like  this. It's  going  to  be  actually  isomorphic  to  that. It's  going  to  look  slightly  different. Let  me  just  make  sure  I  get  this  right. We'll  see  exactly  what  it  looks  like. It's  going  to  look  something  like  this. The  two  xs  are  going  to  be  on  top  of  each  other. In  this  case,  we're  going to  map  all  of  the  points here  to  points  that  look  like  this. Where  the  two  x  again,  they're  on  top  of  each  other. And  now  we  can  easily  a  linear  decision  boundary  that's. We  start  with  a  binary  classification  problem, or  maybe  usually  a  multi  class  classification  problem. Let's  think  about  that  for  1  second. What  is  next  word  prediction? It's  a  multi  classification  problem. There  are  50,000  words  in  English. We're  trying  to  figure  out  which  of  those  50,000 words  is  the  one  that  actually  comes  next. We  want  to  the  word  that  comes  next, it's  in  one  of  50,000  classes  instead  of  just  one  of  two. But  it's  the  same  fundamental  problem. It's  a  multi  class  classification  problem. We  want  to  transform a  impossible  problem  to  start  out with  into  one  that  is  very  straightforward  to  solve. How  do  we  do  that? The  way  that  we  do  that  is we're  going  to  be  transforming problems  into  linearly  separable. I'm  calling  it  like  linearly  separable, meaning  the  different  classes  have a  linear  decision  boundary through  a  sequence  of  two  steps. The  first  is  a  linear  function, basically  matrix  multiplication. Then  the  second  step  is  going  to  be  a  non  linearity. A  multi  layer  perceptron  is  just  repeatedly applying  a  linear  function  followed  by  a  non  linearity. Let's  see  it  applied  in  this  case. The  solution  to  this,  I know  the  transformation  that's going  to  do  the  thing  that  I  want. I'm  just  going  to  write  it  down. I'm  not  going  to  talk  about  learning yet  or  how  I  came  up  with  this. That  will  wait  for  like  next  class. Let's  not  talk  about  learning  yet. Let's  just  imagine  someone can  hand  us  the  correct  solution. What  is  that  solution  look  like? What  do  my  inputs  here  look  like? Four  points. Actually,  let's  write  them  over  here. I  have  four  points  here, I  x  one,  it's  equal  to  00. Sure.  Okay?  I  have  x  two, is  equal  to  10x3, is  equal  to  01x4, is  equal  to  11x1, and  x  four  are  in  the  same  class  together, x  two  and  x  three  are  in  the  same  class  together, I'm  going  to  be  defining  a  function  that maps  each  of  these  four  points  to  new  points  over  here. What  is  my  function  look  like? So  here's  my  function. These  are  vectors,  so  let's  just use  that  orientation  there. My  function  is  going  to  look  like  this. What  is  this  thing? We'll  get  to  that  in  a  minute. We're  going  to  look  at  all  these  pieces. We're  going  to  break  this  down.  But  here's  what our  ultimate  function  is  going  to  look  like. Let's  start  from  the  inside  is  a  matrix. The  first  thing  that  we're  going  to  do  is  take our  input  vectors  x  and  multiply  them  by  a  matrix. What  matrix  will  we  use? We're  going  to  define  a  matrix  W  equals, we're  going  to  define  a  vector  B  which  is  equal  to  this. Let's  see  the  effect  of  this. What  we're  going  to  do  now  is compute  for  each  of  the  four  x  is  over  there, we  have  x  one. What's  that  equal  to?  It's  actually, I  said  minus  one  there. Let's  change  that  to  a  one.  Okay? I  have  a  sign  issue  going  on  here. Just  give  me  1  second. Okay?  It  is  a  minus  one  there. We  have  x  one  plus  B. What's  that  equal  to?  X  one  is  equal  to 00  times  the  zero  vector  is  equal  to  zero  plus  b. It's  equal  to  b,  which  is  zero  minus one  x  two  plus  B.  What's  that  equal  to? X  two  says  get  the  first  column  from. Then  add  this  vector  here. That's  going  to  give  me  103 plus  this  says  get  me  the  second  column from  I  add  it  gives  me  exactly  the  same  thing,  10. Then  finally  I  have  four  plus  B. What's  that  equal  to? Takal  to  21  at. Let's  look  at  just  what  already  happened  here. What  I'm  trying  to  do  is  transform this  into  a  linearly  separable  problem. Let's  imagine  that  I  map  each  of those  four  points  to  the  four  points  I  have  over  there. Let's  see  what  it  looks  like. I  have  a  new  version  of, let's  call  these  things  x  one  prime,  okay? So  it's  like  a  new  version  of  x  one. And  this  is  going  to  be  x  two  prime, this  is  x  three  prime, this  is  equal  to  x  four  prime. What  would  have  happened  if  I  had  stopped  right  there? I  would  have  had  zero  negative  one. I  would  have  had  right  here, that's  where  x  one  gets  mapped  to. I  would  have  had  one. So  I  would  have  had  a  point  right  here  that's where  X  two  and  X  three  get  map  two. It's  interesting,  right?  X  two  and X  three  get  mapped  to  the  same  point. Does  anyone  know  why  that  happened? Look  at  well,  you  know, it's  about  it  has rank  one  project.  Yeah. Well,  what  happened  then  to  x  four? It's  21,  it's  right  here. What  do  you  notice  about  these  three  points? They're  along  a  straight  line  and  that's because  the  matrix  that  we  defined  is  rank  one. Rank  one  matrices  map  everything  onto  a  single  line. Is  this  linearly  separable? Here's  my  positives,  here  are  my  negatives. No,  there's  no  line. I  have  to  draw  a  circle  basically  around  this,  okay? So  I  can't  stop  there  clearly does  not  appear  that  I  have  improved things  at  all  through  that  mapping. You  can  ask  why  did  I  do  it? The  place  that  deep  learning  goes  beyond linear  regression  is  right  here. This  Lu,  what  is  Lulu, is  our  first  and  most  important  non  linearity that  we're  going  to  encounter. This  is  called  the  rectified  linear  function  linear  unit. I  should  say. That  name  is  not  helpful whatsoever  in  terms  of  explaining  what  it  is. It's  a  name,  here's  the  actual  definition  of  it. It's  this  funny  piece  wise  function. Here's  the  rail  function,  It's  zero. For  any  point  below  zero, then  if  you're  above  zero, you  get  mapped  to  yourself. Now  let's  follow  our  instructions  over  here. Let's  do  this  linear  map  here. It's  linear.  Why  am  I  calling  the  linear? Because  it's  just  a  matrix  multiplication  and  addition. It's  a  linear  function. F  function,  we  have  relu of  x  one  plus  B  that's equal  to  u  of  zero,  negative  one. What's  of  zero,  negative  one? And  by  the  way,  when  we're  applying  non  linearities, this  is  a  convention  that  we  have. What's  funny  about  what  I  did  here? I  did  rail  you  of  this, but  here's  how  I  define. Rail  you.  What's  funny  about  that?  It  should  be  funny. It's  not  funny,  but  like,  you  know  what  I  mean? Yeah,  yeah, this  is  a  scalar  up  here  and  this  is  a  vector. So  how  do  we  apply  a  non  linearity  to  an  entire  vector? Well,  what  we  do  is  we  just  apply  it  element  wise. We  apply  it  one  element  at  a  time. Relu  of  zero  is  equal  to  zero. Relu  of  negative  one. Well  we're  in  the  otherwise  case  here, this  just  gets  mapped  to  00. We  have  relu  of  x  two  plus  B that's 10  Lu  does nothing  in  this  case. And  that's  actually  also  equal  to  U  of x  three  plus  B because  x  three  and  x  two  got  mapped  to  the  same  points. Those  are  both  10. Then  we  have  relu x  four  plus  four. So  that's  21  still  21. Relu  only  even  only  applied, only  did  something  to  one  element of  a  single  vector  here. But  it's  magic  and we're  going  to  see  why  it's  magic.  It's  not  magic. Let's  be  honest  here.  All  of  the  math  I'm  teaching  you, you  could  have  done  in  like  your sophomore  year  of  high  school,  right? Or  maybe  even  before  then. There's  no  calculus,  there's  nothing  here. It's  a  very  tiny  amount  of  matrix  multiplication. What  I'm  teaching  you  right  now  is the  most  important  part  of  a  transformer. The  most  important  part  of  GPT  four  is  this. This  is  where  all  the  knowledge  is. Okay? So  let's,  we  had  our  old  map  over  here. We  have  basically  two  graphs. We  have  the  original,  we  had  what things  looked  like  after  only  the  linear  transformation. Now  we're  going  to  have  a,  the  entire  function. We  have  four  points  to  draw. Here  is  x  zero  down  there  are  our new  x0x2  and  x  three  both  get  mapped  to  over  here. Where  is  get  map  to  it  gets  mapped  to 21  gets  mapped  somewhere  over  here. So  I  didn't  quite  get  that  right  up  there  was  close, that's  where  x  four  gets  mapped  to, 0.4  were  negatives,  x  two  and  x  three. We  are  positives.  Is  this  linearly  separable? Yes,  I  can  draw  a  little  line  that  looks  like  this. Okay,  I've  transformed  the  space from  one  in  which  the  different  classes, they  were  all  mixed  together  into  one, where  now  they're  all  separate. I  did  that. Applying  a  linear  function  followed  by  a  non  linearity. That's  deep  learning.  That's  it. There's  nothing  else? Yes,  no,  great  question. I  invented  these  W  and  B  terms. I  invented  them  because  it's a  simple  enough  problem  that  I  can  just figure  out  by  hand  what  the  right  solution  is. Now  the  thing  that  we  know  how  mechanically  build  it, but  we  don't  understand  why  it  works, is  we're  going  to  be  learning  these  W  and  B  matrices. The  matrices  and  the  vectors. We're  going  to  be  learning  them.  We're  going  to  be learning  them  using  stochastic  gradient  descent. They're  going  to  be  huge. Instead  of  being  two  by  two, might  be  20,000  by 20,000  which  maybe  does  not  sound  sufficiently  large. But  think  about  how  many  numbers  are  in a  20,000  by  20,000  matrix. It's  a  lot  of  numbers.  Yes,  ML.  Great  question. The  question  multi  layer  percent, I  haven't  actually  said  what  an  MLP  is yet.  I'll  answer  the  question. The  question  is  whether  MLP  always uses  the  rail  you  as  a  non  linear  function. Traditionally,  no,  the  field  has converged  on  rail  and  Lu  like  things. People  don't  actually  even use  the  railue  in  practice  anymore. But  they  use  something  that's  very slight  variation  on  it, that  has  slightly  better  properties. We'll  be  using  Lu  in this  class  and  it  will  work  fine  for  us. The  field  has  a  very  small  set  of  non  linearities. Yes. Okay,  great  question. So  how  can  we  apply? Let's,  let's  define  the  MLP  and  then  I'll answer  the  general  multilayer perception  and  then  I'll  answer  your  question. Any  other  questions  before  I  get  to That  is  a  very  good  one. Yes.  For  any  given  penis, that  is  a  fantastic  question. Let  me  address  that  also. I'm  going  to  address  that  when  I  talk about  the  general  MLP. Any  others,  it's  fantastic. So  there's  actually,  there's  two  parts  that whether  they  exist  and  whether  it's  learnable, and  those  are  not  necessarily  the  same. Let's,  let's  start  over  here. Let's  do  this.  Okay,  so here's  the  general  form  of  an  MLP. We're  going  to  have  a  sequence  of layers.  This  is  layer  one. Each  layer  is  characterized  by  a potentially  different,  not  necessarily, but  potentially  different,  pair of  weight  matrices  and  offsets. They're  called  biases. And  we're  going  to  have,  let's  say,  k  of  these  layers. An  MLP  applied  to an  input  vector  x  takes  the  following  form. We  first  apply  the  first  layer, we  take  the  first  layer, the  matrix  vector  that  we  have. For  the  first  layer,  we  apply  it, which  means  just  multiply the  input  vector  and  then  add  the  first  bias. What  did  we  then  do?  We  apply a  lue  to  the  result  of  that, we  apply  non  linearity. After  we're  done  with  this,  that is  a  new  vector  that's going  to  serve  as  an  input  to  the  next  layer. We're  going  to  multiply, this  whole  thing  is a  new  vector  because  this  was  a  vector. Then  applying  a  relu,  keeps the  vector,  it's  a  new  vector. We're  going  to  apply  a  new  weight,  matrix  two. We're  going  to  multiply  this  weight matrix  by  this  new  vector. We're  going  to  then  add  the  bias  for  the  second  layer. We're  going  to  apply  a  non linearity  to  the  result  of  that. That  gives  us  a  vector. Let's  move  it  up  there. Mlp  of  x  is  equal  to  this  thing.  What  do  we  do  with  this? We  just  keep  applying  this  process until  we  get  to  the  final  layer. We're  at  the  final  layer, we've  taken  a  new  transformed  vector  as  our  input. We  multiply  that  vector  by our  weight  matrix  K  and  we  add  the  bias  vector  BK. At  that  stage,  we  don't  actually necessarily  apply  non  linearity. It's  actually  conventional  not  to, shouldn't,  it  doesn't  matter  what  I'm  saying. Well,  let's  think  about  one  layer  MLP. If  we  have  a  one  layer  MLP, we  only  have  this  layer  and we  need  to  apply  the  rail  u  at  that  layer, or  else  the  MLP  is  just  a  linear  function  in  that  case, which  doesn't  help  us. Okay,  so  good, we've  figured  out  that  we  need  to  apply the  MLP  at  the  layer. Yes,  sure. That  fantastic  question. The  question  is  about  dimensionality. You  need  to  always  make  sure that  your  weight  matrices  and  biases are  of  the  correct  dimensionality  that  are compatible  with  the  next  layer. So  you  can't  just  choose these  things  independent  of  each  other. This  outputs  a  ten  dimensional  vector. This  needs  to  take  as  input  a  ten  dimensional  vector. The  output  dimensions  of  layer I  need  to  match  the  input  dimensions  of  layer  I  plus  one. That  answers  the  question  I  think  from  back  there about  what  happens  if  we're not  in  a  two  dimensional  problem.  It's  fine. X  can  be  a  vector  of  any  dimension  that  we  want. As  long  as  the  first  weight  matrix  that the  appropriate  dimension  is input  has  the  right  number  of  columns,  basically. Okay,  There  was  a  question  about what  types  of  functions  can  we  represent  here? There's  something  called the  Universal  Approximation  Theorem. It  is  the  most  famous  and  useless  theorem  in  this  area. The  theorem  says  that  sufficiently  smooth  function, I'm  not  going  to  give  a  definition  of  smooth. But  basically,  for  any  sufficiently  smooth  function there  exists  a  one  layer. That's  actually  pretty  surprising. A  one  layer  MLP  that  can  approximate  that  function. You  need,  I  think,  an  additional weight  matrix  on  the  outside. In  that  case,  it's  basically, maybe  not  quite  one  layer  as  we  defined  it  here, but  it's  only  one  layer  with a  non  linearity  followed  by  a  linear  transformation. The  reason  it's  useless  is  that  it  does  not  tell us  anything  about  ability. You  can  have  all  sorts  of  functions  that,  in  principle, you  can  represent  with  an  MLP that  are  impossible  to  in  practice. It  doesn't  say  anything  about  that. It  also  doesn't  say  that  how much  data  do  you  need  to  learn  it? Right?  You're  going  to  be  learning these  things  from  data. Doesn't  say  anything  about  that. Any  other  questions? Let's  talk  about  one  last  thing. Let  me  give  you  a  visual  representation of  the  MLP  and  this  is a  very  common  way that  people  think  about  this  here  we've. Again,  giving  the  functional  form  of  this, We  can  also  think  about  this  as  a  diagram. We  have  our  input  vector  x. We're  going  to  represent  by a  sequence  of  we  can  call  them  neurons  or activations  would  mean  each of  these  neurons  corresponds  to a  different  slot  in this  vector  x,  the  different  coordinates. We  have  a  vector  x  of  dimensionality. Three  has  three  coordinates, x1x2  and  x  three. We're  just  going  to  p,  this is  maybe  written  a  little  bit  small  for people  in  the  back,  I  apologize  about  that. We're  going  to  place  each  of those  coordinates  inside  of  one  of  these  slots  here, inside  one  of  these  neurons. Our  weight  matrix. The  weight  matrix  in  the  first  layer  is  going  to map  these  three  neurons  to  some  new  set  of  neurons. Might  be  three.  It  might  be  four. It  might  be  two  or  might  be  one. Let's  say  it's  two. The  way  that  we're  going  to  indicate this  mapping  is  using  lines. We're  going  to  have  a  line from  each  neuron  into  each  new  neuron. These  lines  are  going  to  basically the  weights  in  this  weight  matrix. Let's  call  for  right  now, this  is  Y  one  and  Y  two. The  way  that  we  can  read  this  is  that  we  have a  y  vector  which  consists of  these  two  neurons  or  activations. This  is  equal  to  one  times  x. Now,  why  do  we  have  these  lines  here? The  lines  stand  in  for  the  weights  in  this  weight  matrix. How  big  is  this  weight  matrix? Where  are  its  dimensions? Yes,  which  is  it? Okay,  we  can  figure  it  out. Actually,  yeah,  two  by  three. Why  did  you  say  two  by  three? X  is  three  by  one.  Exactly.  So  we're  going  to  have.
