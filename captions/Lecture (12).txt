Okay,  so  let's  talk  to  GBT  3.5  a  little  bit. Okay,  Take  the  last  layer of  the  words  and  make  them  the  first  layer  of  the  words. These  are  not  really  words,  maybe  that's  not  nice. Random,  straight  now,  this does  not  seem  like  a  very  complicated  task. It's  a  slightly  weird  task, but  average  what  age  would  you  guess  can  solve  this  task? How  old  do  you  have  to  be?  I  would guess  like  fourth  grade  or  something. You  could  probably  do  this  pretty  reliably. Gp  3.5  is  definitely  smarter  than  a  fourth  grader. The  free  version,  you've  talked  a  lot, It  can  do  many  things  a  fourth  grader  cannot  do. Let's  look  at  this. I  want  to  take  the  last  letter  and  make  it  the  first. Let  n  be  a  bunch  of  A's  followed  by  a  single  N,  right? That's  not  right,  it's  missing  N. What  about  this  one? It  should  take  the  A,  move  that  to  the  front, it's  ASD,  then  be  KJ. What  happened  to  the  D  at  the  end  of  this? And  there  might  be  another  missing  letter  here. Take  the  move  it  to  the  front.  What  happened  here? I  don't  see  an  S  at  the  front  of  this. It  just  dropped  the  ball  on  this  in  a  way  that  yeah, like  age  range  for  being  able  to  do. My  guess  is  like  ten  years  old. There  are  probably  smart  six  year  olds  that  can  do  this. Is  PT  the  free  version, is  it  not  as  smart  as  a  six  year  old  or  a  ten  year  old? No,  clearly  very  intelligent  in  some  ways. It's  reasonably  intelligent  in some  ways  what's  going  on  here. That's  one  of  the  things  we're  going  to  be  learning. But  today  we're  going  to  start  to  learn  about  this  today. Why  did  this  model  fail  at  this  task  so  easily? The  reason  I  didn't  do  this  with  T  four  is  that these  errors  are  harder  to  find  with  GPT  four, but  they're  actually  still  there. You  have  to  come  up  with slightly  more  complicated  examples. But  basically  anything  that has  to  do  with  the  structure  of  words, like  what's  inside  of  a  word  P  four  is  much  more likely  to  fail  than  you  would  think  if we  think  these  models have  a  certain  level  of  intelligence. Subtract  many  levels  off of  that  intelligence  when  it  comes  to the  task  of  manipulating words  like  what's  inside  of  a  word. We'll  learn  a  little  bit  about  why  that's  true  today. My  department  chair  is  also  here  today  in  the  back. Sorry,  I  didn't  mean  to. The  reason  I'm  telling  all  of  you this  is  I  need your  help  to  make  sure  I  don't  get  fired,  okay? I  need  a  very  cooperative  audience  today, okay?  So,  you  know, for  the  last  4.5  weeks  actually  it's  been  five  weeks. Now,  this  is  exactly  like  a  five  week  mark. For  the  last  five  weeks, we've  been  just  going  through very  general  deep  learning  stuff. Nothing  different  about  what  we've  been learning  versus  what  you would  learn  about  in  any  other  class. Introducing  deep  learning,  assuming  they shared  my  perspective  on  the  field  as  a  whole. Today  is  going  to  be  like  the  first distinctively  language  components  of the  class  we're  going to  learn  about  how  do  you  actually  build neural  networks  for  dealing with  language  and  some  of the  challenges  that  are  involved  there. Let's  say  that  I  want  to  build  a  sentiment  classifier that  hot  dog  was  nasty,  very  practical  problem. We  want  to  know,  was  this  a  positive  review of  the  hot  dog  or  a  negative  review  of  the  hot  dog? We're  going  to  run  this  sentence through  a  neural  network. That's  why  we've  been  introducing  neural  networks. We're  going  to  run  this  sentence through  a  neural  network. And  the  neural  network  is  to  give  us  an  answer. At  the  end,  it's  going  to  give  us  a  probability, was  the  hot  dog,  is  the  sentence  positive  or  negative? Trying  to  do  a  binary  classification. Now  there's  something  that  should strike  you  as  slightly  funny  about  this, the  task  of  turning sentences  into  something  that can  be  fed  through  a  neural  network. Why  is  this  funny?  Let  me  put  it  another  way. Every  year  some  people  have a  bit  of  a  hang  up  about  how  this  could  even  make  sense. It  does  seem  almost  sounds  like  gibberish. Put  a  sentence  into  a  neural  network.  Is  it  gibberish? Why  it  sound  like  gibberish? Yeah,  I  love  how  do  you  get  words. How  do  you  get  the  words  into  numbers? Neural  networks  process  numbers. I  have  words  here.  Words  are  not  numbers. Now,  okay, it's  true  that  does  seem  to present  a  barrier  to  doing  this. But  let's  go  back  and  remember our  philosophy  for  how  to  do  deep  learning, which  is  do  the  dumbest  thing  possible. At  every  stage,  we should  try  to  do  the  dumbest  thing  possible. There  are  many  dumb  things  actually  I  can  do  here. Maybe  we  actually  don't  want  to  choose the  very  dumbest  something that  is  pretty  far on  the  spectrum  of  being  dumb that  we  actually  end  up  doing  here. Does  anyone  want  to  make  a  guess? Assuming  you  have  not  seen  this  before? Yeah,  okay,  great. Assign  a  distinct  number to  each  word  and  then  that  number. Let's  do  that.  The  correct  answer  is  very  close  to  that. Let's  say  that  this  is  word  five. This  is  word  seven. This  is  word  29. This  is  word  117, and  then  this  is  word  one. I  just  made  up  the  numbers. Do  you  think  I  should  do  that? Well,  let's  say  that  we let's  talk  about  this  a  little  bit  more about  how  this  assignment  process  goes. We're  going  to  have  a  vocabulary,  the  vocabulary, vocabulary  means  the  distinct  words  in  the  language. It's  a  set  of  distinct  words  in  the  language. A  set  of  words  is  an  English  word. We  really  construct  such  a  thing. We  go  through  all  of  English, we  collect  all  of  the  unique  words  in  English. It's  much  worse  than  that  or much  more  expansive  than  that  because  as  you  know, GPT  four  can  handle  many  different  languages. We  actually  have  to  go  through  basically  all  of the  words  that  exist  in  almost  any  language. There  are  going  to  be  clever  things  that  we  do. Be  honest,  let's  just  stick  to English  right  now  because  we  have  to do  smarter  things  when  we, not  too  smart,  a  little  smart when  we  encounter  other  languages. Make  a  guess  for  how  many  distinct  words there  are  in  English. When  we're  thinking  about  this, we  have  to  realize  that  we  have  to  be  able  to  deal  with any  sentence  that  is  thrown  at  us  on  the  internet. Any  word  that's  thrown  at  us  on  the  Internet. People  say  lots  of  weird  stuff  on  the  Internet. If  you  collect  up  all  of  that  weird  stuff, does  anyone  want  to  make  a  guess? Distinct  things,  can  people  say  on the  Internet  there  with  spaces  in  between  them, let's  say  that  occur  reasonably  often, not  just  like  one  off things  like  100,000  it's  in  the  hundreds  of  thousands, It's  more  than  100,000  It  would, depending  on  what  threshold  you  use, it's  going  to  be  somewhere  in  100,000  300,000  let's  say. Now  that's  a  very  big  vocabulary. It's  bigger  than  what  people  use  in  practice. The  largest  vocabularies  that  people  use  in practice  are  around  100,000  And  you can  get  it  down  to  50,000  or  something  and  still keep  most  of  the  frequent  words  that  people  use. 50,000  I  would  say  is  like  a  minimum  for  what  would count  as  a  word  in  English you  would  recognize  if  you want  to  deal  with  all  the  weird  stuff, you  either  have  to  do  something  slightly  clever, which  we'll  get  to  later, or  you  have  to  use  a  much  larger  vocabulary. Okay,  we  have  our  vocabulary. We're  going  to  create  a  mapping  of mapping  of  words  in  our  vocabulary  to  natural  numbers. We're  just  going  to  all  of the  of  W  is just  going  to  equal  the  function  applied  to  some  word. Is  just  going  to  be  like,  what  position does  that  word  occur  in  the  vocabulary? We're  just  going  to  order  the  vocabulary in  some  way.  It  could  be  however  we  want. It  doesn't  really  matter.  Each  word gets  a  distinct  number. So  we  actually  do  this. So  the  idea  of assigning  every  word  in  the  sentence  a  number, we  actually  end  up  doing  that. Okay?  So  we've  transformed words  into  numbers.  What  could  we  do  then? I  mean,  I  think  the  simplest  thing  to  do  would  be just  run  this  directly  through  the  neural  network. Okay,  How  do  I  do  that? How  do  I  run  these  numbers  through  a  neural  network? Someone  give  me  an  idea  for a  neural  network  architecture  that  I could  use  to  process  this  sentence. And  then  do  sentiment  classification. Yeah,  okay.  And  then  what  do  I  do  with  that? Give  me  what's  the  name  of that  thing  that  we've  been  doing. There's  really  only  one  architecture we've  looked  at  so  far. What  was  that  architecture? The  multi  layer  perceptron. So  we  can  just  run  this  through  a  multi  layer  perceptron. So  this  is  a  vector  now. Right,  we  have. We  have  an  input  node. This  is  12,  34x5. We  have  an  input  node  for every  word  we  just use  our  normal  multi  layer  perceptron  architecture. Here  is  the  multi  layer  perceptron. Do  it  says  you  have  a  hidden  layer. I'm  going  to  have  a  hidden  layer  here. I  don't  know  how  many  nodes I'll  include  in  the  hidden  layer. Let's  say  it's  three. This  is  123. I  draw  arrows,  it's  fully  connected. I  draw  arrows  from  each  input  node  to  each  node. Here  I  take  a  rail, you,  I  have  my  hidden  state. Finally,  I'm  going  to  have  a  single  output  node. I'll,  I'll  call  this  one. Then  I  have  the  probability  of  positive, of  positive,  given  this  input  vector x  is  equal  to  sigmoid. My  sigmoid  function  of  one. I  just  ran  the  sentence  through  a  multi  layer  perceptron. I  get  an  output  score  for  the  sentence. If  this  score  is  higher, then  you're  more  likely  to  be  a  positive  sentence. If  it's  lower,  you're  less likely  to  be  a  positive  sentence. Any  questions  about  that? No.  Okay. This  is  in  fact, close  to  the  simplest  thing  that  you  can  do here  that  will  maybe  start  to  give  you  decent  results. There's  one  basic  problem  with  what  I  just  sketched  out. There  are  other  problems  that  are  more  interesting. But  there's  one  basic  problem  like  this. It  takes  every  word  on  a  position. Yeah.  That  would  make  some  words  greater  than other  words.  That's  exactly  right. We're  positioning  the  words  on  a  line. That's  not  a  meaningful  thing  to  do. Our  original  ranking  was  completely  arbitrary,  right? We  just  ordered  the  words  maybe  alphabetically, maybe  at  random,  maybe  we  did  some  other  way. There's  no  uniform  way  where  you can  position  your  words  on  a  line. In  general,  neural  networks, continuous  functions, not  necessarily  differentiable  as we've  learned  about,  but  they  are  continuous. What  that  means  is  that  when  you change  the  inputs  to  a  neural  network  by  a  little  bit, what  happens  in  general, when  I  change  the  input  to a  neural  network  by  a  small  amount? What  do  I  expect? What's  the  definition  of  a  continuous  function? Yeah,  values  change  by  a  little  by  words, maybe  there's  a  really  positive  words. Negative  words.  67. Exactly.  Let's  suppose  that  just  by  chance  the  word got  assigned  to  number  two,  it  could  happen. The  word  great  just  happens  to  be  next  to  the  word  nasty. Change  the  input  to  the  network  by  a  little  bit. I  changed  it  1-2  In  general, I  should  not  expect  this  change  to result  in  a  large  change  in  the  network. Yes. I  mean,  they're  there  in  the  sense that  whenever  you  see  me  drawing  lines, there's  a  weight  matrix  there.  We  can  give  them  a  name. And  just  I'm,  I'm  assuming  that  we  all  know  how  to  do, how  to  compute  the  a  vector  and  from  these  weights, but  yes,  they're  there. Absolutely. It's  the  same  MLP  architecture  that  we  talked  about. Just  like  only  one  output  node. Now  that's  the  only  difference,  okay? Basically,  it  may  not  make sense  all  of  the  words  in  my  language  on  a  single  line. Even  if  I  can  come  up  with  the  best  possible  line, there's  no  meaningful  order that  I  can  impose  on  all  of  the  words. What  we  do,  instead  of  trying to  put  everything  onto  a  line, is  we  assign  every  word  in  the  language  a  vector. We  call  these  things  word  vectors. Why  is  it  better  to  assign  every  word  of vector  instead  of  a  single  number? It's  that  a  vector  can contain  much  more  information  in  it. The  vectors  that  we're  talking  about  here  have anywhere  300-10  thousand  dimensions  in  them. The  word  vectors  are  going  to  contain basically  all  the  information  about  what  that  word  means, the  information  that  the  neural  network  needs to  know  about  what  that  word  means. It's  not  just  saying  the  word  lies  in  a  line. It's  saying  this  word. There  are  300  dimensions  along  which  words  can  vary. And  we're  going  to  say  along each  dimension  where  that  word  fits, we're  going  to  have  300  features, at  least  for  every  word. There's  a  question,  how  do  we  assign  these  word  vectors? We'll  get  to  that  in  a  minute. How  do  you  actually  build  good  word  vectors? I  haven't  said  anything  about  that  yet. I  just  want  to  go  through  a  few  mechanical  things. So we're  going  to have  a  set  of word  vectors,  V,  I, for  every  word  in  the  vocabulary. We're  going  to  have  a  distinct  word  vector. What  we're  going  to  do  is  we're  going to  pack  these  word  vectors  into  a  matrix. It's  going  to  be  a  matrix where  the  first  column is  going  to  be  the  first  word  vector. What's  our  Vocab  size? Let's  call  Vocab  size. Let's  just  give  it  a  name, the  size  of  vocabularies. So  there  are  going  to  be  columns  in  this  matrix. We're  going  to  use  this  matrix  in  order  to  retrieve the  word  vector  for  any  particular  word. So  when  we  encounter  a  word, we're  going  to  map  that  word to  what's  called  a  one  hot  encoding. A  one  hot  encoding  equals a  vector  of  all  zeros  except  for  a  single  one. We're  going  to  have  a  vector  that  is  all  zero  everywhere, except  in  a  single  position where  there's  a  one  in  that  position. Let's  say  that  we  have  a  word. Let's  say  that  we  have  a  word,  k. We  go  up  there,  we  find  for a  particular  word,  what  is  it? What's  its  value  of?  Let's  say  I  have  Bob  is  equal  to, I  don't  want  to  do  something  that  big. Let's  say  it's  equal  to  three is  the  third  word  in  our  vocabulary. I  create  a  one  hot  vector. One  hot  for  Bob  is equal  to  a  new  vector of  all  zeros  except  at  the  third  position. Let  me  pause  there  for  a  second. I  took  my  entire  vocabulary. I  ordered  all  of  the  words  in  some  way. Bob  happened  to  be  the  third  word  in  that  vocabulary. He  got  lucky. We're  going  to  map  Bob  to  a  new  one,  hot  vector. The  one  hot  vector  is  just  filled  with  zero  is except  at  position  three because  that  was  the  rank  of  Bob. Yes,  the  size  of  that  vector. The  size  of  that  vector  is  the  size  of  the  vocabulary. I'm  going  to  then  use  one  hot  Bob. That  wasn't  intentional. I  promise  you  to  retrieve  the  word  vector  for  Bob. How  do  I  do  that?  How  can I  use  this  vector  and  assume  it's  actually, I  wrote  it  here  as  a  row  vector because  I  didn't  have  space. But  assume  this  is  actually  a  column  vector, assuming  it's  pointed  like  this, How  can  I  use  this  vector  in that  matrix  to  retrieve  the  word  vector  for  Bob? Yeah,  I  can  multiply  the  vector  by  the  matrix. Exactly.  I'm  going  to  multiply  this  by  one  hot  Bob. Actually,  I'm  going  to  use an  arrow  there  because  it's  actually a  vector  that  give  me,  it  gives  me  V  three. The  one  hot  vector  just  says  if  it's a  position  find  element, find  the  th  column  of  this  matrix. In  this  case  it's  three. For  some  other  word  it  would  be  K. If  k  is  the  index  of  that  word, we'll,  I'll  use  different  names  for  this  thing. Okay,  We  got  V  three  out. I  can,  sometimes  I'll call  that  Bob  because  it's  the  word, just  different  names  for  the  same  thing. I  might  also  sometimes  just  like  Bob's  vector. I  hope  it'll  be  pretty  clear  when  this  comes  up, different  notations  for  what's the  vector  that's  assigned  to  Bob. Can  anyone  take  a  guess  about  why  we  went through  this  whole  exercise of  turning  Bob  into  a  one  hot  vector, then  doing  this  matrix  multiplication  by this  matrix  of  word  vectors  in order  to  retrieve  the  vector  for  Bob. Why  did  we  do  this? We  want  to  take  a  guess. It  has  to  do  with  what  we  were  doing  last  class. Yeah,  you  can  apply  batching. We  can  apply  batching  to  this.  What  do  you  mean  by  that? You  could  multiply  any  number  of  one  object. Exactly  how  would  I  do  that? So  let's  say  I  have  just, let's  say  two  words  like  Bob  is. What  can  I  do  to retrieve  the  word  vectors  for  those  two  words? You  put  them  together  as  a  column  matrix. Multiply  them  by  vat. Okay,  great.  We'll  keep  writing  it  out  like  this. Actually,  let  me  give  you  the  name  right  now. This  is  usually  called  our  embedding  matrix. I'll  call  it  for  embedding. Whenever  you  hear  the  term  embedding  matrix, this  is  what  people  are  referring  to. They're  referring  to  this  matrix where  you  collect  up  all  the  words  in the  vocabulary  and  you  assign each  of  them  a  distinct  vector. For  Bob  is  what  we'd  like  to  do  is  map  both  Bob  and Is  efficiently  to  their  word  vectors. We're  going  to  take, we're  going  to  multiply  that  by a  new  matrix  that  we  construct. Where  the  first  column  is  Bob,  Bob, it's  one  hot  Bob,  that's  the  first  column. And  then  the  second  column  is  one  hot. For  is  what  happens  when  I  do  this  matrix  multiplication. I  get  back  a  new  matrix  that  has  two  columns  in  it. The  first  column  will  be, well  it's  the  column  for  one  hot  Bob times  the  embedding  matrix. That's  the  word  vector  for the  second  column  that  I  get  back  is  the  word  vector  for. I  can  do  this  for  as  many  words  as  I  want. Now,  in  practice,  these  embedding  matrices  are a  big  pain  point  for  dealing  with  in  practice. These  are  the  largest  matrices that  appear  anywhere  in  your  model. In  some  cases,  basically, unless  you're  working  with  an  extremely  large  model, at  least  the  billions  of  parameters, maybe  tens  of  billions  of  parameters, These  embedding  matrices  take up  like  a  very  large  fraction  of all  of  the  weights  that  your  model  has. Why  is  that? Because  the  vocabulary  size  that  you're  working  with  is typically  large,  This  dimension  here. What  are  the  rows  represent? I  said  it  was  like  300  to 10,000  features  that  you're  assigning  to  every  word. Let's  say  it's  300. That's  a  practical  size  model. You  have  to  have  a  number  of columns  equal  to  the  number  of  words. How  many  words  are  your  vocabulary? As  I  said,  it  might  very  easily  be 50,000  That's  on  the  low  end, what  people  typically  use. You  have  a  300  by  50,000  matrix.  That's  a  big  matrix. You're  not  going  to  have  any other  matrices  in  your  model  that have  50,000  50,000  is  one  of  their  dimensions. It'll  typically  be  like  300  by 1,200  or  something  like  this. Matrix  can  easily  be  50  times larger  than  any  other  matrix  that  you  see  in  your  model. Until  you  start  getting  to  very  big  models, it's  a  pain  to  deal  with  for  that  reason. In  practice,  people  actually  do  something even  more  clever  than  this  than  this  batching  here. We're  not  going  to  go  over  that, just  to  say  dealing  with  this  thing  is  a  pain. You  can  think  of  the  way  that  it's dealt  with  as  batching  and  until  you're dealing  with  very  advanced  use  cases, you  won't  be  too  off. Yes, Yeah,  yes,  Yes. That's  exactly  right.  Yeah,  yeah. Yeah.  That's  going  to  be,  I  mean,  it's  a  pain. Yeah.  You  actually,  basically  what  you  end  up having  to  do  is  represent  this  thing as  sort  of  like  a  sparse  matrix. So  you  don't  represent  this  as a  normal  matrix  programming. There's  a  special  data  type  called a  sparse  matrix  where  you know  that  most  of  the  entries  are  zero. If  you  know  that  most  of  the  entries  are, all  that  you  have  to  do  is  represent the  non  zero  entries. The  memory  footprint  of  this  in  practice  only  ends  up being  the  length  of  the  sentence, like  this  one  be  represented  by  the  number  three. This  one  would  be  represented  by the  index  of  the  word  is. But  mathematically  it's  the  same  as  this  is. There's  a  clever  trick  under  the  hood  that  you  get  to  do. It's  a  great  observation.  Yeah. It  may  be  rank  zero,  that's  one  way. It  might  be  different  than  the  identity  matrix. You  could  have  the  same  word  occurring. The  identity  matrix  is  very  special  because  it's square  and  then  it's  all  on  the  diagonal. Here  are  the  ones  that  are  not  necessarily  diagonal. They  could  all  occur  in  the  same  row. For  example,  if  it's the  same  word  repeated  over  and  over  and  over  again. Yeah, Okay. You're  raising  a  really  fantastic  issue right  now,  which  is  what  happens. There  are  several  questions  that  you've  asked. Let's  start  with  the  simplest  one, which  is  what  do  you  do when  you  encounter  a  word  that's  not  in  your  vocabulary? There's  something  very  simple  that  people  do. That  basically  is  still  done  in  practice. You  have  a  special  word  in your  vocabulary  which  is  UN  K,  for  unknown. You  encounter  a  word  you've  never  seen  before, you  assign  it  to  the  word  vector  for  the  special  word. If  my  normal  vocabulary  has  50,000  words  in  it, I  actually  include  a  50001st  special  word that  whenever  I  encounter, I  don't  know,  I  use  that  thing, I  substitute  that  word  instead. What  do  you  do?  What  happens if  you  encounter  a  word  that  looks  like another  word  but  you  don't  have the  word  in  your  vocabulary, It's  a  little  bit  dangerous  to  map  it. You're  talking  about  a  fractional  approach. I  don't  immediately  see  how  that  would  work. You  could  imagine  maybe  something  a little  bit  simpler  than  a  fractional  approach, which  is  map  this  weird  new  word to  the  nearest  word  in  your  vocabulary. You  run  a  spell  checker  on  it  and  you  see  what's  the  most likely  match  the  danger  there  is. You  may  end  up  corrupting  the  nearby  words. You,  you  see  some  weird  word. Your  spell  checker  assigns that  weird  word  to  some  actual  word  in  your  vocabulary, the  actual  word  in  the  vocabulary. It  may  end  up  getting  corrupted  by  having  been  assigned, having  been  matched  with  this  weird  word. Because  maybe  the  weird  word doesn't  actually  correspond  to that  real  word.  This  is  a  sub  point. Let  me  get  back  to  this  in  a  little  bit. Dealing  with  the  weird  stuff  that  people  say  in  practice, which  is  something  that  you  really  have  to  do. People  misspell  in  all  sorts  of  weird  ways. People  use  slang  and  jargon  that  you've  not encountered  before  or  not  thought about  and  was  not  in  your  training  set. Being  able  to  deal  with  this  is  actually a  pain  point  for  basically  every  existing  model. There's  no  good  solution  right  now. There  are  things  that  people do  that  work  better  than  other  things, but  there's  no  real  solution  to  this  issue. I'd  say  it's  the  thing  where  it's  like  people have  been  happy  to  ignore  it for  as  long  as  they  can and  just  sweep  the  problem  under  the  rug. But  it's  like  it  keeps  getting  exposed. Okay,  now  at,  this  might  be a  good  time  to  go  back  to  the  beginning  of  lecture  and the  failure  that  we  observed  for  ChachiPT. What  were  we  asking  Chachi  BT  to  do  at  that  time? We  were  asking  PT  to some  weird  word  that  it  had never  probably  seen  before,  A, R,  G,  L, A  and  then  take the  last  letter  of  this  word  and  put  it  at  the  front. And  what  we  saw  is  it  couldn't  do  it. It  was  giving  us  stuff  back.  Take  the  last  letter. What  we  actually  want  is L  what  Chachi  BT  was  actually  producing  was  like  GTL. That's  nonsense. That's  not  what  we  wanted. We  don't  need  to  worry  about  this  right  now. I  don't  want  to  distract  you  with that  issue  that  I  just  brought  up. But  can  we  think  in  terms  of the  architecture  that  we've  written  down  here? Why  will  it  be  hard  for  models? Manipulate  the  internal  structure  of  words. That's  what  we're  asking  the  model  to  do. Take  a  word  like  this  and turn  around  the  letters  in  the  word  in  some  way. Why  do  we  expect  that  to  be had  for  models  that  have  this  type  of  architecture? Yeah,  because  they're  given  the  whole  words. These  are  two  words  that  as humans  we  can  immediately  recognize, that's  A  and  pajama. For  those  of  you  who  are being  unfortunately  blocked  by  this, Ama  and  pajama  are  two  words  that  we  can  immediately recognize  as  having  similar,  similar  internal  structure. They  rhyme  with  each  other,  that's why  I  have  to  read  a  book  every  night that  talks  about  mama  going  to  sleep  in  his  pajamas. Toddlers  can  recognize  the  similarity in  the  structure  of  these  words. Obviously  the  rhyme,  They  look  the  same, At  least  after  a  certain  point. From  the  perspective  of  the  model  though, what  does  the  model  see? The  model  sees  this  word  ma  got index  205  in  that  list  up  there. I  listed  all  of  my  vocabulary. It  was  number  205  in  that  list. That's  the  only  thing  that  the  model  sees  about this  word  lama  pajama, where  the  model  see  about  that. It  saw  this  was  in 15,219  The  model  on this  assigned  gosign  index and  they  each  got  separate  vectors. As  a  result,  it  doesn't  actually  get access  to  the  internal  structure of  the  words  in  any  direct  way. That's  true  for  basically  every  model. There's  a  wrinkle  on  this  that  we'll  talk about  in  maybe  a  few  lectures. To  a  first  approximation,  though, that's  what  the  model  sees  about  these  words. With  that  in  mind,  I  want  to  take  a  look  at  one  thing. So  someone  give  me  two  words  that  rhyme. I'm  not  going  to  use  llama  in  pajama  because it  knows  about  the  book  series  there. Give  me  two  words  that  rhyme  Someone. Yeah.  And  fat.  Okay? Okay.  So  four  knows  about  them rhyming  and  knows  that  they  look  similar. I  want  to  emphasize  to  everyone  this  is  not information  that  GP  four  has directly  accessible  to  it  in  the  way  that  we  do, GPT  four  does  not  see  the  word as  AT  the  way  that  it  sees  the  word. It  was  like  word 256  in  my  vocabulary  list.  The  same  thing  for  fat. It  still  knows  all  of  this  stuff  basically. It's  hard  to  almost  find  an  analogy  for  this, but  it's  someone  who learned  to  play  music  without  being  able  to  hear. So  it's  very  similar  to  someone  who  learned  to play  music  just  by  reading  about  music  almost. That's  the  closest  analogy  that  I can  think  of  for  the  ability  that  you're  seeing  here. What  happened  is  that  GBD  four  saw  the  words  cat. It  saw  index  256  and  index 719  being  used  so  much  that  it  figured out  properties  of  what must  be  true  of  this  word  for  it  to  be  used  in  this  way. Them  rhyming  would  explain why  they're  used  together  in  this  way. It  basically  discovered  a  concept  of  rhyming  without actually  knowing  anything  about  what  rhyming  sounds  like. It  can  tell  us  actually  about  what rhyming  sounds  like  or  the  experience  of rhyming  without  ever  having experience  to  rhyme  for  itself. This  is  a  weird  issue  having to  do  with  language  models  and  it  all  goes back  to  these  one  hot  encodings that  we  use  for  the  words. Yeah, Yeah,  that's  a  great  question. You're  asking  the  same  great  question. Okay,  good  observation. So  these  two  are  a  little  funny  and  it has  to  do  with  a  because  they  are  long  words. There's  a  wrinkle  in  terms  of  what  I've  been  talking about  that  might  not  be  true  here.  Gp  four. They're  longer  words  and  that changes  things  a  little  bit. But  it  knows  they  both  end  in  phone. Saxophone  directly  related  to  music. All  phone  is  directly  related  to  the  sound. Okay?  Greek  roots. So  Red  knows  all  of this  stuff  might  be  cheating  a little  bit  or  at  least  it  may  not  be  quite  as  limited. Give  me  if  anyone  can  think  of  a  case, the  best  test  case  would  be  two  words  that  sound similar  but  do  not  share  the  same  written  root. Yeah,  great, that's  a  good  example. This  is  now,  it's  just  yesingI's a  great  one. Let  me  ask,  let, I  just  want  to  continue  with  this  one. Let  me  ask  a  leading  question  here. So  it  did  not  get  this  at  all. This  one  is  pretty  funny,  okay? I  asked  the  leading  question, but  maybe  they  don't  technically  rhyme. That  might  be,  so  we  can  tell  they  rhyme. Maybe  GPT  doesn't  quite  have  the  concept  of  a  Hyka. It's  not  a  bad  answer  for  something that  cannot  see  the  internal  structure  of these  words  and  cannot  hear  them  either. I  would  say  do  so. Do  you  have  an  example  of  two  words that  seem  like  they  should  rhyme  but  don't? Okay,  It's  a  good  idea.  What's  that? Rough? So  rough  and  what?  Oh,  plow,  Okay,  great. All  right,  well  so  B  four definitely  it  does  not  see  that  rough  has  UGH. That's  not  seen  by  the  model  at  all  in  a  direct  way. This  is  something  the  model  had  to  learn by  somehow  picking  it  up  implicitly  from  the  text. These  words  are  pronounced  quite differently  even  though  they  end  in  UH, plow  rhymes  with  rough,  rhymes  with  tough. It's  like  factual  knowledge  that  the  model independently  pick  up  at  each  of  these  independent  words. Yeah. Okay,  That's  great.  You're  right. And  I  actually  think  there  is  evidence  for that  that  some  of  the  rows, I  think  you  mean  some  of the  features  can  actually  indicate  what  letters. Now,  it's  not  clear  how  often  that's  actually  useful. Think  about  these  models  only  have  so  many  features. You  don't  want  to  waste  features  on  letters  in  general. That's  not  going  to be  a  very  useful  thing  for  prediction. Meaning  always  is  more  important than  the  surface  form  of  a  word. When  you're  listening  to  me  talk. It's  not  like  you're  going  through  and processing  every  letter  of  what  I'm  saying. You're  trying  to  ignore the  sound  as  soon  as  you can  in  order  to  focus  on  the  meaning. The  models  are  doing  something  similar,  but  you're  right. In  principle,  the  models  could, it  would  have  to  be  learned,  but  they  could  learn. Like  they  could  assign  independent features  to  different  letters. I  suspect  they  do something  much  more  efficient  than  that. But  yes,  that  ultimately will  end  up  being  what  they're  doing. There  is  a  comment  or  question  over  here. Yeah,  yeah. Okay,  so  tell  me  about  a  word that  rhymes  with  again  in  England, but  not  in  America. Okay,  there  we  go.  So  it  knows  this. I  mean,  we  look, you  know,  it's  seen  a  huge  training  corpus. Some  of  this  might  just  be  memorized. It  can  definitely  do  some  novel  reasoning though  you  can  test  it  out  on weird  stuff  it's  never  seen  before. Gpt  four  has  gotten  much better  dealing  with  these  issues. Pt  3.5  as  you  saw  is complete  trash,  uncharacteristically  trash. Given  that  it's  the  free  chat  PT,  it's  unusually  bad. Yeah,  I could  recognize  the  similarity  there. Almost  certainly.  Yes.  I  mean, at  least  for  the  simple  cases,  you  should  test  it  out. If  you  get  something  weird,  let  me  know. Yeah,  yeah, let's  see.  Yeah,  this  is  wrong. You're  absolutely  right.  This  parts  right. Again.  Again?  No,  Sorry. No,  it's  not.  It's  again.  Right. But  it's  wrong.  As  again. Yeah.  No,  that's  not  right.  Yeah.  Okay.  So  look. Okay,  so  we  already  okay.  Yeah.  So  Canadian. Yeah.  But  this  is  not  America. Not  my  America. Okay. Yeah. I  would  say  that  that's  like an  uncharacteristically  dumb  mistake  for  GP  four. You're  not  going  to  find  many  other  domains  where P  four  fails  on  such  simple  cases. But  if  you  want  to  find  like  very  simple  failures to  convince  yourselves  that GP  four  is  not  a  big  deal,  this  is  the  place  to  do  it. It  has  to  do  just  with  what  GT  four  is  perceiving. Let's  go  back  over  here. Let's  actually  draw  out  a  new  diagram. So  let  me  just  write  back  in  some  numbers. I  hope  they'll  approximately  correspond to  the  numbers  that  I  wrote  down  before. Okay. Instead  of  assigning  a  single  number to  each  order  and  stopping  there, we're  not  going  to  directly  feed the  numbers  into  the  neural  network,  right? We  are  still  assigning  numbers  to  each  word. The  index  in  the  vocabulary, what  position  are  you  in  the  vocabulary? We're  still  going  to  do  that,  unlike in  that  neural  network  up  there, we're  not  going  to  feed  them  directly  in. What  we're  going  to  do  instead is  assign  each  word  vector. We're  going  to  look  up  its  word  vector. We  replace  the  word  with  the  word  vector  for. We  look  that  up  with  the  one  hot  encoding. We  can  ignore  that  detail  for  right  now. We  look  up  the  word  vector  for  hot, for,  for,  was  for  nasty. What  do  we  do  now?  I  want  to  feed  this  into  an  MLP. There's  different  things  I  can  do  here. It's  at  this  stage, basically  what  the  rest  of  the  course  is  going  to  be about  is  what  do  we  do? Now,  all  architectures  that  people use  for  natural  language  processing  start  with  this  step. Everything  you  transform  words  into  vectors. Just  a  big  look  up  table  basically, which  is  this  matrix  E  you're  embedding  matrix. You  look  up  for  every  word,  what's  the  word  vector? Then  the  interesting  stuff starts,  what  do  you  actually  do  with  this? Let's  just  imagine  for  right  now  that  we  wanted  to feed  these  word  vectors  into  our  MLP. Our  MLP,  let's  say, has  a  hidden  dimension  of  three. I'm  in  a  slightly  different  situation now  than  I  was  before. How  do  I  go  from  these  word  vectors  to something  that  can  be  mapped  into? I  want  to  take  these  word  vectors  and then  map  them  into  hidden  states. I'm  going  to  use  still  a  linear  model  to  do  that. I'm  going  to  just  matrix multiplication,  but  how  do  I  do  that? What's  a  little  bit  different between  this  problem  and  the  problem  that  I  had  up  there? I  want  to  think  about  this.  Let's  say  I  want  to  draw an  edge  between  this  vector  and  a  one. Did  you  have  a  suggestion? Yeah,  go  ahead.  Yeah,  yeah,  exactly. It's  you've  hit  the  nail.  That's  exactly  right. Previously  in  all  the  other  examples  I've done  appear  in  previous  classes, the  input  to  my  MLP  was  a  single  vector. Now,  the  input  to  my  MLP is  actually  a  sequence  of  vectors. It's  like  five  vectors  in  this  case. What  do  I  do? Yeah,  I could  do  something  like  that. A  sequence  length  basically by  tensor,  something  like  that.  Is  that  right? So  that's  one  solution  for  the  time  being. Let  me  suggest  an  even  simpler  solution. Maybe  someone  wants  to  propose  an  even  simpler  solution. There's  a  very,  very  simple  thing  that  we  can  do  to actually  turn  this  problem  basically  into  that  problem, into  the  standard  problem  that  we've  been  working  with. There's  fancier  things  that  you  can  do. Exactly  along  the  lines  of  what  you're  suggesting. Yeah, from  here  you  mean?  Great  question. This  is  I  went through  my  vocabulary,  I  ordered  everything. Some  word,  that's  the  first  word. This  is  the  vector  for  whatever  the  first  word  is. This  thing  that  I  have  over  here, this  is,  someone  gives  me a  particular  word  and  I  want  to look  up  what's  its  word  embedding. That's  what  I'm  saying  there.  Bob  is in  one  of  these  columns  here. Like  I  don't  know  what  its  index  is  though. Like  me  personally,  I  just  don't  know. But  it's  somewhere  in  there  and  we  could  find  it  if  we needed  to.  Great  question. Okay,  what's  the  simplest  thing  that  I  could  do to  turn  this  problem  into  a  standard  MLP  problem? Yeah. I  can  just  concatenate  the  vectors. I'm  not  saying  that's  a  good  idea, but  it's  something  I  can  do  and then  everything  will  just  work  out. I'm  going  to  write  down,  I'll just  write  down  the  same  arrows  here. I'll  say  what  exactly  this  means. The  notation  itself  is  ambiguous. This  arrow  notation, let's  say  what  these  arrows  actually  mean. We're  going  to  have  a  vector, let's  call it our  sequence  vector. It's  equal  to  the  concatenation of  hot all  the  way  through  nasty. I  concatenate  those  five  words  together. I  put  those  together  into  a  sequence  vector. Now  I  just  have  a  vector  that  is five  times  the  length  of  any  of  these  individual  vectors. Then  a  new  vector  a  is  just  equal  to  my  weight  matrix, one  times  sequence  vector. The  same  thing  I  could  have  over  there. I  run  a  through  a  relu, I  have  a  hidden  vector  h  that's  equal  to  Relu  of  a. I  have  my  output  node one  that  takes  as  input  each  of  the  H  I  have  one, one  is  equal  to  two  times. Finally,  I  have  p  is  equal  to  sigmoid  of  one. And  then  I  use  that's  the  probability  of  positive. This  is  a  negative  sentence, right?  What  do  I  do? I  compute  the  loss  that  knowing  that  that is  negative  loss  will  actually  be  equal  to, uh,  the  negative  log  probability of  negative. Given  my  sequence,  I  have  my  input  sequence  vector. I  calculate  the  negative  log  prob, the  negative  log  probability  of  the  negative  category. What's  the  probability  of  the  negative  category? Is  the  probability  of  positive? This  is  a  positive  sentence. What's  the  probability  of  negative  then? Yeah,  it  was  one  minus  exactly. I  can  calculate  my  loss  from  this. Then  what  do  I  do?  I  just  back  propagate, I  compute  the  gradient. I'm  just  going  to run  stochastic  gradient  descent  on  this. Now,  there  was  a  question that  should  have  been haunting  everyone,  this  whole  class, which  is  I  have  my  embedding  matrix  here, consists  of  word  embeddings  for  every  word. Where  did  this  thing  come  from? How  do  I  get  a  good  vector  representation  for  words? What  is  deep  learning  tell  us  to  do  there? Yeah,  we're  going  to  start  randomly. That's  true,  because  that's dumb,  that's  a  good  thing  to  do. So  we're  going  to  initialize  our  word  vectors  randomly, but  that  will  not  result  in  good  word  vectors. They're  just  going  to  be  randomly  distributed. Where  do  I  get  good  word  vectors  from? What  does  back  propagation  allow  us  to  do? Think  about  that  from  the  perspective of  my  word  embeddings. What  is  back  propagation  allow  us  to  do? Yeah,  exactly. I  can  go  back  and  look at  each  of  these  five  words  here  and ask  how  does  changing the  vector  representation  for these  words  change  the  loss? I  use  that  to  calculate  a  gradient. The  gradient  of  the  loss  with  respect to  these  word  embeddings. That's  how  I'm  going  to  learn  good  word  vectors, the  deep  learning  solution. If  you  don't  know  something, there's  something  that's  missing  from  your  model. Where  it's  like  it's  in  your  model but  you  don't  know  how  to  set  it  right. Like  I  don't  know  how  to  define  my  word  embeddings. If  you  told  me  what's  a  good  word, embedding  for  these  five  words that's  300  dimensional,  I  would  have  no  clue. I  would  really  no  idea  how  to  start. The  deep  learning  solution  to  this  is just  them.  How  you  learn  them. You  learn  them  with  back  propagation and  stochastic  radian  descent. Anything  that  you  don't  know,  you  learn. The  way  that  you  learn  it  is  by seeing  what  setting  will  improve  the  loss. How  can  we  change  them  in such  a  way  that  the  loss  goes  down? And  we  make  better  predictions. We're  optimizing  our  word  embeddings, just  like  we're  optimizing  everything  else  in the  model  in  order  to  make  good  predictions. Yeah, it's  different. In  this  case.  I'm  not  changing  the  input, I'm  changing  the  representation  of  the  input. You. Well,  you  have  just  discovered  the  reason  why people  used  to  not  use  multi  layer  perceptron, still  do  not  use multilayer  perceptrons alone  for  natural  language  processing. Can  you  say  more  about  this? Okay,  okay,  fine. So  we  have  a  network  architecture that  looks  like  to  me  like  it's  fixed,  right? If  someone  were  to  input  a  sixth  word  here, what  would  we  do  with  that  sixth  word? Nothing  like  my  weight  matrices, they  have  fixed  dimension,  right? So  I  don't  know  what  to  do  with  that  sixth  word. It  can't,  it  can't  be  part of  the  weight  matrix  multiplication. Also,  I'll  get  like  dimension, I'll  be  out  of  bounds  in  my  dimensions,  right? So  that's  no  good.  So  yeah, this  is  a  big  problem  here. I  used  to  think  that  this  was like  an  obvious  reason  why  you could  not  use  multilayer  perceptrons for  processing  sentences. But  there  are,  I  think  I've  mentioned several  times  that  the  field  is converging  around  multilayer  perceptrons. Again,  how  is  that  possible? I  mean,  it  turns  out  that even  transformers  models  PT  four. In  the  best  case,  we'll  stop  working Well  after  you  exceed  a  certain  context  length, the  context  length  that  you  can  use  with GPT  is  32,000  That's like  the  longest  input  that  you  can  give. 32,000  tokens. That  means  like  25,000  words. That  exact  conversion  doesn't  matter  what, basically  it's  a  fixed  quantity. Technically  run  the  architecture with  longer  inputs,  it  will  not  work. We,  we'll  talk  about  the  reasons  for  that. For  most  existing  architectures, even  though  in  principle  they  can deal  with  arbitrarily  long  inputs, it's  actually  quite  challenging. Usually  they  work  well  up  to  a  fixed  input  length. Let's  say  32,000  words  or  something  like  that. What  could  you  do  if  you  wanted to  process  really  long  sentences  or really  long  texts  with  an  MLP and  also  process  shorter  texts  at  the  same  time. What  would  be  the  dumbest  possible  solution  to  that? I  want  an  MLP  that  can  process  up  to  32,000  words, but  I  also  want  it  to  be  able  to  process  words with  five  sentences,  with  five  words  in  them. What  could  I  do?  Yeah,  have  it  be  unnecessarily  big. I  could  extend.  There's  one  wrinkle there  that  we'll  have  to  talk  about. I  have  word  one,  word  two  up  to  word 32,000  Then  I  have  my  MLP  here. And  it  goes  like  that. I  just  make  this  unnecessarily  big. Whenever  I  encounter  a  sentence, whenever  I  input  a  text  or  a  sentence, I  put  in  that  sentence  or  text  as  the  first  K  words  here. And  then  I  just  fill  out  the  rest  of  it with  a  special  token, a  token  that's  all  zeros  or a  special  token  that  a  special  type  of  padding  to, that's  what  people  would  call  it, a  special  padding  token. And  the  model  to  the  model  to  ignore. Whenever  you  see  this  padding  here, it's  nothing  there,  just  ignore  it. Now  you  can  accommodate  sentences that  text  with  up  to  32,000  words  in  them. That's  the  longest  that  you  can actually  handle  with  transformers  like  GPT  four. You're  not  any  worse  off. There's  another  reason  why the  MLP  is  actually  not  quite  as  good  as  transformers at  has  not  probably  fully  caught  on yet.  It's  more  subtle. This  length  issue  is  a  very  important  one, I  don't  think  this  is  the  real  killer. There's  a  more  subtle  issue. We'll  talk  about  that  next time  for  right  now.  Let's  call  it  a  day. Thank  you  for  not  getting  me  fired.
